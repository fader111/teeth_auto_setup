{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "энкодер- декодер на основе сверточной сети. надо сделать не fit модели а train step."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# from keras.datasets import mnist\r\n",
    "import numpy as np\r\n",
    "# from jaw_gen import *\r\n",
    "import tensorflow\r\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape\r\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization\r\n",
    "from tensorflow.keras.models import Model\r\n",
    "\r\n",
    "import tensorflow.keras.backend as K\r\n",
    "from tensorflow.keras.layers import Lambda\r\n",
    "import cv2\r\n",
    "\r\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# import keras\r\n",
    "print (f\"keras ver.{tensorflow.keras.__version__}\")\r\n",
    "# print (f\"keras ver.{1}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "keras ver.2.6.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# класс который генерит картинки размерностью с искривлениями зубов или без.\r\n",
    "\r\n",
    "# print(f\" cv2 ver. {cv2.__version__}, np ver. {np.__version__}\")\r\n",
    "np.random.seed() # устанавливает режим случайных чисел без повторений от запуска к запуску\r\n",
    "\r\n",
    "class Landmark_gen():\r\n",
    "    ''' creates pictures with incistor edges landmarks '''\r\n",
    "\r\n",
    "    def __init__(self, number=100, dim=(200, 200)):\r\n",
    "        self.number = number\r\n",
    "        self.dim = dim\r\n",
    "\r\n",
    "    def image_gen(  self, \r\n",
    "                    name='_', \r\n",
    "                    scale1=1, \r\n",
    "                    factor=2.6, \r\n",
    "                    shift_x=0, \r\n",
    "                    shift_y=0, \r\n",
    "                    spoiled = False,    # вводит хаотичный наклон и смещение зубов имитируя T1\r\n",
    "                    shiftX = False,     # add random shift for whole tooth for X axis\r\n",
    "                    shiftY = False,     # add random shift for whole tooth for Y axis\r\n",
    "                    show=False):\r\n",
    "        # встроить сюда еще смещение \r\n",
    "        # все делаем под разрешение 200x200 \r\n",
    "        self.back = np.zeros((200, 200))            # картинка с ровными зубами\r\n",
    "        self.back_spoiled = np.zeros((200,200))     # картинка с корявыми зубами\r\n",
    "        self.factor = factor\r\n",
    "        center = (100, 100)\r\n",
    "\r\n",
    "        # оси координат по центру\r\n",
    "        if 1:\r\n",
    "            cv2.line(self.back, (0, center[1]), (200, center[1]), 0.4, 1)\r\n",
    "            cv2.line(self.back, (center[0], 0), (center[0], 200), 0.4, 1)\r\n",
    "            cv2.line(self.back_spoiled, (0, center[1]), (200, center[1]), 0.4, 1)\r\n",
    "            cv2.line(self.back_spoiled, (center[0], 0), (center[0], 200), 0.4, 1)\r\n",
    "\r\n",
    "        # строим дугу. так чтобы на основе ее точек можно было зубья подровнять\r\n",
    "        for i in range(-8, 8):\r\n",
    "            # строим точки графика\r\n",
    "            # первая точка зуба\r\n",
    "            point_ = [int(i*scale1)+center[0], int(self.duga(i)) + center[1]]\r\n",
    "            # вторая\r\n",
    "            point2_ = [int((i+1-0.2)*scale1 +\r\n",
    "                          center[0]), int(self.duga(i+1-0.2)) + center[1]]\r\n",
    "            \r\n",
    "            # строим линии по дуге - ровные зубы\r\n",
    "            cv2.line(self.back, point_, point2_, 1, 2)\r\n",
    "\r\n",
    "            # шатаем зубы если задано шатать и выдаем на картинку back_spoiled\r\n",
    "            if spoiled: \r\n",
    "                if i in [-8, -7, -6, 5, 6, 7 ]: # портим моляры \r\n",
    "                    point_[0]+= int((np.random.sample()-1)*i)\r\n",
    "\r\n",
    "                if i in [-5, -4, -3, -2, 1, 2, 3, 4]: # премоляры и резцы\r\n",
    "                    point_[1]+= int((np.random.sample()-1)*i*2)\r\n",
    "\r\n",
    "                if i in [-1, 0]: # передние резцы\r\n",
    "                    point_[1]+= int((np.random.sample()-1)*4)\r\n",
    "            \r\n",
    "            if shiftX:\r\n",
    "                case_shift_x_ = int((np.random.sample()-1)*5)\r\n",
    "                point_[0] += case_shift_x_\r\n",
    "                point2_[0] += case_shift_x_\r\n",
    "            \r\n",
    "            if shiftY:\r\n",
    "                case_shift_y_ = int((np.random.sample()-1)*5)\r\n",
    "                point_[1] += case_shift_y_\r\n",
    "                point2_[1] += case_shift_y_\r\n",
    "            \r\n",
    "            # для второй картинки сторим покореженные зубы. или те-же если корежить не надо\r\n",
    "            cv2.line(self.back_spoiled, point_, point2_, 1, 2)\r\n",
    "            \r\n",
    "            # cv2.circle(self.back, point_, 1, 0.2, 1)\r\n",
    "        # print (f\"self.back shape {self.back.shape}\")\r\n",
    "\r\n",
    "        if show: # shows picture. beware using in batсh processing\r\n",
    "            self.back = cv2.resize(self.back, self.dim)  # увеличиваем только для показа\r\n",
    "            self.back_spoiled = cv2.resize(self.back_spoiled, self.dim)  # увеличиваем только для показа\r\n",
    "            img_for_show = np.hstack((self.back, self.back_spoiled))\r\n",
    "            cv2.imshow(name, img_for_show)\r\n",
    "            k = cv2.waitKey()\r\n",
    "\r\n",
    "        return self.back, self.back_spoiled  \r\n",
    "\r\n",
    "    def duga(self, x):\r\n",
    "        ''' returns arc function'''\r\n",
    "        return abs(x)**self.factor - 200 * 0.35"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# готовим входные данные\r\n",
    "inst_ = Landmark_gen()\r\n",
    "data_len = 10000\r\n",
    "dataset = []\r\n",
    "dataset_spoiled = []\r\n",
    "\r\n",
    "for i in range(data_len):\r\n",
    "    scale =  9 + np.random.sample()*3     # это для размера 200, диапазон от 14 до 19 для размера 400\r\n",
    "    factor = 2.2 + np.random.sample()/4   # это для размера 200, диапазон 2.5 - 2.7 для размера 400 \r\n",
    "    # name = f\"scale {scale:.4}  factor {factor:.3}\"\r\n",
    "    img_, img_spoiled_ = inst_.image_gen(scale1=scale, factor=factor, spoiled=True, shiftX=True, shift_y=True)\r\n",
    "    dataset.append(img_)\r\n",
    "    dataset_spoiled.append(img_spoiled_)\r\n",
    "\r\n",
    "\r\n",
    "set_divider_ = round(data_len*0.8)\r\n",
    "# print (f\"set_divider_ {set_divider_}\")\r\n",
    "\r\n",
    "x_train = dataset[:set_divider_]\r\n",
    "x_test = dataset[set_divider_:]\r\n",
    "# print (f\"length {len(x_train)} - {len(x_test)}\")\r\n",
    "\r\n",
    "x_train_spoiled = dataset_spoiled[:set_divider_]\r\n",
    "x_test_spoiled = dataset_spoiled[set_divider_:]\r\n",
    "\r\n",
    "# конвертнем данные\r\n",
    "x_train = np.array(x_train, dtype=\"float32\")    # x_train = x_train.astype('float32') / 255. \r\n",
    "x_test  = np.array(x_test, dtype=\"float32\")      # x_test  = x_test .astype('float32') / 255.\r\n",
    "x_train = np.reshape(x_train, (len(x_train), 200, 200, 1))\r\n",
    "x_test  = np.reshape(x_test,  (len(x_test),  200, 200, 1))\r\n",
    "\r\n",
    "x_train_spoiled = np.array(x_train_spoiled, dtype=\"float32\")   \r\n",
    "x_test_spoiled  = np.array(x_test_spoiled, dtype=\"float32\")    \r\n",
    "x_train_spoiled = np.reshape(x_train_spoiled, (len(x_train_spoiled), 200, 200, 1))\r\n",
    "x_test_spoiled  = np.reshape(x_test_spoiled,  (len(x_test_spoiled),  200, 200, 1))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def create_deep_conv_ae():\r\n",
    "    input_img = Input(shape=(200, 200, 1))\r\n",
    "\r\n",
    "    x = Conv2D(128, (7, 7), activation='relu', padding='same')(input_img)\r\n",
    "    x= BatchNormalization()(x)\r\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\r\n",
    "    x= BatchNormalization()(x)\r\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\r\n",
    "    x= BatchNormalization()(x)\r\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\r\n",
    "    x= BatchNormalization()(x)\r\n",
    "    encoded = Conv2D(1, (3, 3), activation='relu', padding='same')(x) # в оригинале тут оставался один фильтр. \r\n",
    "\r\n",
    "    # На этом моменте представление  (50, 50, 8) т.е. 20000-размерное нихера сибе. посмотрим как будет учиться Уже нет. уже (50, 50, 1)\r\n",
    "\r\n",
    "    input_encoded = Input(shape=(50, 50, 1))\r\n",
    "    x = Conv2D(32, (7, 7), activation='relu', padding='same')(input_encoded)\r\n",
    "    x= BatchNormalization()(x)\r\n",
    "    x = UpSampling2D((2, 2))(x)\r\n",
    "    x= BatchNormalization()(x)\r\n",
    "    x = Conv2D(128, (2, 2), activation='relu', padding='same')(x)\r\n",
    "    x= BatchNormalization()(x)\r\n",
    "    x = UpSampling2D((2, 2))(x)\r\n",
    "    x= BatchNormalization()(x)\r\n",
    "    decoded = Conv2D(1, (7, 7), activation='sigmoid', padding='same')(x)\r\n",
    "\r\n",
    "    # Модели\r\n",
    "    encoder = Model(input_img, encoded, name=\"encoder\")\r\n",
    "    decoder = Model(input_encoded, decoded, name=\"decoder\")\r\n",
    "    autoencoder = Model(input_img, decoder(encoder(input_img)), name=\"autoencoder\")\r\n",
    "    return encoder, decoder, autoencoder\r\n",
    "\r\n",
    "c_encoder, c_decoder, c_autoencoder = create_deep_conv_ae()\r\n",
    "c_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\r\n",
    "\r\n",
    "# c_autoencoder.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "batch_size = 8\r\n",
    "\r\n",
    "def create_denoising_model(autoencoder):\r\n",
    "    def add_noise(x):\r\n",
    "        noise_factor = 0.5\r\n",
    "        # x = x + K.random_normal(x.get_shape(), 0.5, noise_factor) # не шумим. тсс...\r\n",
    "        x = K.clip(x, 0., 1.)\r\n",
    "        return x\r\n",
    "\r\n",
    "    input_img  = Input(batch_shape=(batch_size, 200, 200, 1))\r\n",
    "    input_img_spoiled  = Input(batch_shape=(batch_size, 200, 200, 1)) # вход для кореженных зубьев\r\n",
    "\r\n",
    "    # noised_img = Lambda(add_noise)(input_img) # больше не нужен шум\r\n",
    "\r\n",
    "    # noiser = Model(input_img, noised_img, name=\"noiser\") # и моделька шумелка не нужна\r\n",
    "    # denoiser_model = Model(input_img, autoencoder(noiser(input_img)), name=\"denoiser\") # это старая оригинальная модель\r\n",
    "    denoiser_model = Model([input_img, input_img_spoiled], autoencoder(input_img_spoiled), name=\"denoiser\")\r\n",
    "    # return noiser, denoiser_model\r\n",
    "    return denoiser_model\r\n",
    "\r\n",
    "\r\n",
    "# noiser, denoiser_model = create_denoising_model(c_autoencoder)\r\n",
    "denoiser_model = create_denoising_model(c_autoencoder)\r\n",
    "denoiser_model.compile(optimizer='adam', loss='binary_crossentropy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "%matplotlib inline\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "def plot_digits(*args):\r\n",
    "    args = [x.squeeze() for x in args]\r\n",
    "    n = min([x.shape[0] for x in args])\r\n",
    "    \r\n",
    "    plt.figure(figsize=(2*n, 2*len(args)))\r\n",
    "    for j in range(n):\r\n",
    "            for i in range(len(args)):\r\n",
    "                ax = plt.subplot(len(args), n, i*n + j + 1)\r\n",
    "                plt.imshow(args[i][j])\r\n",
    "                plt.gray()\r\n",
    "                ax.get_xaxis().set_visible(False)\r\n",
    "                ax.get_yaxis().set_visible(False)\r\n",
    "\r\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# вместо фита будем делать  model.train_on_batch читобы смотреть как учится и куда движемся\r\n",
    "def train_on_batch(x, x_spoil, batch_size=batch_size, epochs=100):\r\n",
    "    # подровняем массив обучащих так чтоб np.reshape не ругался на несовпадение размерности\r\n",
    "    x = x[:len(x_train)//batch_size*batch_size]\r\n",
    "    x = np.reshape(x, (-1, batch_size, 200, 200, 1)) # x_test  = np.reshape(x_test,  (len(x_test),  200, 200, 1))\r\n",
    "    \r\n",
    "    # и массив кореженных тоже\r\n",
    "    x_spoil = x_spoil[:len(x_train_spoiled)//batch_size*batch_size]\r\n",
    "    x_spoil = np.reshape(x_spoil, (-1, batch_size, 200, 200, 1)) \r\n",
    "    \r\n",
    "    for epoch in range(1, epochs+1):\r\n",
    "        print(f\"Epoch {epoch}\")\r\n",
    "        for i, _ in enumerate(tqdm(x)):\r\n",
    "            batch_x = x[i]\r\n",
    "            batch_x_spoiled = x_spoil[i]\r\n",
    "            denoiser_model.train_on_batch([batch_x, batch_x_spoiled], batch_x)\r\n",
    "\r\n",
    "        # эпоха отучилась, построим что вышло.\r\n",
    "        n = 10\r\n",
    "        imgs = batch_x\r\n",
    "        # noised_imgs = noiser.predict(imgs, batch_size=batch_size)\r\n",
    "        noised_imgs = batch_x_spoiled\r\n",
    "        encoded_imgs = c_encoder.predict(noised_imgs[:n],  batch_size=n)\r\n",
    "        decoded_imgs = c_decoder.predict(encoded_imgs[:n], batch_size=n)\r\n",
    "\r\n",
    "        # рисуем картинки и сохраняем модели\r\n",
    "        if (epoch % 20 ==0) or (epoch in [1,2,3,5,10]):\r\n",
    "            plot_digits(imgs[:n], noised_imgs, decoded_imgs)\r\n",
    "            denoiser_model.save(f'models/denoiser_1_flt_{epoch}ep.h5')\r\n",
    "            c_decoder.save(f'models/c_decoder_1_flt_{epoch}ep.h5')\r\n",
    "            c_encoder.save(f'models/c_encoder_1_flt_{epoch}ep.h5')\r\n",
    "        \r\n",
    "# train_on_batch(x_train, batch_size=batch_size, epochs=100)\r\n",
    "train_on_batch(x_train, x_train_spoiled, batch_size=batch_size, epochs=100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/1000 [00:16<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3144/683887005.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;31m# train_on_batch(x_train, batch_size=batch_size, epochs=100)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train_spoiled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3144/683887005.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(x, x_spoil, batch_size, epochs)\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mbatch_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mbatch_x_spoiled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_spoil\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mdenoiser_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_x_spoiled\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# эпоха отучилась, построим что вышло.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   1854\u001b[0m                                                     class_weight)\n\u001b[0;32m   1855\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1856\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1858\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3040\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1964\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# c_autoencoder.save(f'models/c_autoencoder.h5')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "n = 10\r\n",
    "\r\n",
    "imgs = x_test[:batch_size]\r\n",
    "noised_imgs = noiser.predict(imgs, batch_size=batch_size)\r\n",
    "encoded_imgs = с_encoder.predict(noised_imgs[:n],  batch_size=n)\r\n",
    "decoded_imgs = с_decoder.predict(encoded_imgs[:n], batch_size=n)\r\n",
    "\r\n",
    "plot_digits(imgs[:n], noised_imgs, decoded_imgs)\r\n",
    "# plot_digits(imgs[:n], decoded_imgs)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "encoded_imgs[:20]"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit"
  },
  "interpreter": {
   "hash": "04635d289a519a1410467dd0afb0db42f9184808881ca68b2eb5a687a20a5a94"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}