{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "3D энкодер- декодер. Отличие от предыдущей версии - вместо растра точек на вход сети подать вектора лендмарков в виде набора координат и длин."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# from keras.datasets import mnist\r\n",
    "import numpy as np\r\n",
    "# from jaw_gen import *\r\n",
    "import tensorflow as tf \r\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Dropout\r\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization\r\n",
    "from tensorflow.keras.models import Model\r\n",
    "from tensorflow.keras.optimizers import Adam\r\n",
    "\r\n",
    "import tensorflow.keras.backend as K\r\n",
    "from tensorflow.keras.layers import Lambda\r\n",
    "import cv2\r\n",
    "\r\n",
    "from tqdm import tqdm\r\n",
    "# основное отличие - Landmark_gen больше не генерит картинки. только вектора. \r\n",
    "# и у него теперь есть 3D рисовалка, которая есть независимый метод\r\n",
    "from jaw_gen3d import Landmark_gen "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# готовим входные данные\r\n",
    "inst_ =                 Landmark_gen()\r\n",
    "data_len =              50000\r\n",
    "dataset =               []\r\n",
    "dataset_spoiled =       []\r\n",
    "dataset_vec =           []\r\n",
    "dataset_vec_spoiled =   []\r\n",
    "\r\n",
    "for i in range(data_len):\r\n",
    "    scale =  9 + np.random.sample()*3     # это для размера 200, диапазон от 14 до 19 для размера 400\r\n",
    "    factor = 2.2 + np.random.sample()/4   # это для размера 200, диапазон 2.5 - 2.7 для размера 400 \r\n",
    "    # name = f\"scale {scale:.4}  factor {factor:.3}\"\r\n",
    "    vec, vec_spoiled = inst_.image_gen(scale=scale, factor=factor, spoiled=True, shiftX=True, shiftY=True)\r\n",
    "    # dataset.append(img_)\r\n",
    "    # dataset_spoiled.append(img_spoiled_)\r\n",
    "\r\n",
    "    # собираем датасет из векторов \r\n",
    "    dataset_vec.append(vec)\r\n",
    "    dataset_vec_spoiled.append(vec_spoiled)\r\n",
    "# print (f\"dataset_vec {dataset_vec[:1]}\")\r\n",
    "print (f\"dataset_vec len {len(dataset_vec)} \")\r\n",
    "print (f\"dataset_vec_spoiled len {len(dataset_vec_spoiled)} \")\r\n",
    "\r\n",
    "# преобразуем датасет в numpy массив\r\n",
    "# dataset =               np.array(dataset,               dtype=\"float32\")    # x_train = x_train.astype('float32') / 255. \r\n",
    "# dataset_spoiled =       np.array(dataset_spoiled,       dtype=\"float32\") \r\n",
    "dataset_vec =           np.array(dataset_vec,           dtype=\"float32\") \r\n",
    "dataset_vec_spoiled =   np.array(dataset_vec_spoiled,   dtype=\"float32\") \r\n",
    "\r\n",
    "# dataset =           np.reshape(dataset,         (len(dataset), 200, 200, 1))\r\n",
    "# dataset_spoiled =   np.reshape(dataset_spoiled, (len(dataset_spoiled), 200, 200, 1))\r\n",
    "\r\n",
    "# разобьем датасет на тренировочную и тестовую части\r\n",
    "set_divider_ = round(data_len*0.8)\r\n",
    "# print (f\"set_divider_ {set_divider_}\")\r\n",
    "\r\n",
    "# x_train = dataset[:set_divider_]\r\n",
    "# x_test = dataset[set_divider_:]\r\n",
    "# print (f\"length {len(x_train)} - {len(x_test)}\")\r\n",
    "\r\n",
    "# x_train_spoiled = dataset_spoiled[:set_divider_]\r\n",
    "# x_test_spoiled = dataset_spoiled[set_divider_:]\r\n",
    "\r\n",
    "# векторный датасет\r\n",
    "x_train_vec =   dataset_vec[:set_divider_]\r\n",
    "x_test_vec =    dataset_vec[set_divider_:]\r\n",
    "# print (f\"length vec {len(x_train_vec)} - {len(x_test_vec)}\")\r\n",
    "\r\n",
    "x_train_vec_spoiled =   dataset_vec_spoiled[:set_divider_]\r\n",
    "x_test_vec_spoiled =    dataset_vec_spoiled[set_divider_:]\r\n",
    "# print (f\"vec [0]{x_test_vec[0]}\")\r\n",
    "print (f\"length vec         {len(x_train_vec)} - {len(x_test_vec)}\")\r\n",
    "print (f\"length vec spoil   {len(x_train_vec_spoiled)} - {len(x_test_vec_spoiled)}\")\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dataset_vec len 50000 \n",
      "dataset_vec_spoiled len 50000 \n",
      "length vec         40000 - 10000\n",
      "length vec spoil   40000 - 10000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def create_vec_ae3D():\r\n",
    "    # 3d кодер - декодер содержит на входе 6*16=96 значений.\r\n",
    "    dim_code = 16 # размерность кодированного слоя\r\n",
    "    activation = 'elu' \r\n",
    "    # activation = 'linear'\r\n",
    "    inputs = Input(96,)\r\n",
    "    WITH_BN = True # go with batcNormalization\r\n",
    "\r\n",
    "    # encoder\r\n",
    "    x = Dense(96, activation=activation)(inputs)\r\n",
    "    x= BatchNormalization()(x)      if WITH_BN else x\r\n",
    "    x = Dense(96, activation=activation)(x)\r\n",
    "    x= BatchNormalization()(x)      if WITH_BN else x\r\n",
    "    code = Dense(dim_code, activation='linear')(x)\r\n",
    "\r\n",
    "    # decoder\r\n",
    "    input_encoded = Input((dim_code,))\r\n",
    "    x = Dense(dim_code, activation=activation)(input_encoded)\r\n",
    "    x= BatchNormalization()(x)      if WITH_BN else x\r\n",
    "    x = Dense(96, activation=activation)(x)\r\n",
    "    x= BatchNormalization()(x)      if WITH_BN else x\r\n",
    "    out = Dense(96, activation='linear')(x)\r\n",
    "    \r\n",
    "    # Модели\r\n",
    "    encoder = Model(inputs, code, name=\"encoder\")\r\n",
    "    decoder = Model(input_encoded, out, name=\"decoder\")\r\n",
    "    autoencoder = Model(inputs, decoder(encoder(inputs)), name=\"autoencoder\")\r\n",
    "    return encoder, decoder, autoencoder\r\n",
    "\r\n",
    "encoder, decoder, autoencoder = create_vec_ae3D()\r\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\r\n",
    "# autoencoder.compile(Adam(0.003), 'mse')\r\n",
    "\r\n",
    "# c_autoencoder.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "batch_size = 256\r\n",
    "\r\n",
    "def create_denoising_model(autoencoder):\r\n",
    "    \r\n",
    "    inputs  = Input(batch_shape=(batch_size, 96))\r\n",
    "    inputs_spoiled  = Input(batch_shape=(batch_size, 96)) # вход для кореженных зубьев\r\n",
    "\r\n",
    "    denoiser_model = Model([inputs, inputs_spoiled], autoencoder(inputs_spoiled), name=\"denoiser\")\r\n",
    "    # return noiser, denoiser_model\r\n",
    "    return denoiser_model\r\n",
    "\r\n",
    "\r\n",
    "# noiser, denoiser_model = create_denoising_model(c_autoencoder)\r\n",
    "denoiser_model = create_denoising_model(autoencoder)\r\n",
    "denoiser_model.compile(optimizer='adam', loss='mean_squared_error')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "%matplotlib inline\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "def plot_digits(*args):\r\n",
    "    # for a in args:\r\n",
    "        # print (f\"type args {type(a)}\")\r\n",
    "    args = [x.squeeze() for x in args]\r\n",
    "    n = min([x.shape[0] for x in args])\r\n",
    "    \r\n",
    "    plt.figure(figsize=(2*n, 2*len(args)))\r\n",
    "    for j in range(n):\r\n",
    "            for i in range(len(args)):\r\n",
    "                ax = plt.subplot(len(args), n, i*n + j + 1)\r\n",
    "                plt.imshow(args[i][j])\r\n",
    "                plt.gray()\r\n",
    "                ax.get_xaxis().set_visible(False)\r\n",
    "                ax.get_yaxis().set_visible(False)\r\n",
    "\r\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "%matplotlib inline\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "def plot_3d(*args):\r\n",
    "    # \r\n",
    "    n = min([x.shape[0] for x in args]) # сколько столбцов\r\n",
    "    plt.figure(figsize=(2*n, 2*len(args)))\r\n",
    "    for j in range(n):\r\n",
    "        for i in range(len(args)):\r\n",
    "            pass #ax = plt.\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# вместо фита будем делать  model.train_on_batch читобы смотреть как учится и куда движемся\r\n",
    "def train_on_batch(vec, vec_spoil, batch_size=batch_size, epochs=100):\r\n",
    "    # подровняем массив картинок и обучающих векторов так, чтоб np.reshape не ругался - на несовпадение размерности\r\n",
    "    # сделаем его длину кратной размеру батча\r\n",
    "    # print (f\"x_train_vec.shape {x_train_vec.shape}\")    # (8000, 16, 6)\r\n",
    "    # print (f\"vec shape {vec.shape}\")                    # (8000, 16, 6)\r\n",
    "    # print (f\"vec_spoil shape {vec_spoil.shape}\")        # (8000, 16, 6)\r\n",
    "\r\n",
    "    # x =     x   [:len(x_train)//    batch_size*batch_size]\r\n",
    "    vec =   vec [:len(x_train_vec)//batch_size*batch_size]\r\n",
    "    # x =     np.reshape(x,   (-1, batch_size, 200, 200, 1))  # x_test  = np.reshape(x_test,  (len(x_test),  200, 200, 1))\r\n",
    "    vec =   np.reshape(vec, (-1, batch_size, 96))           # x_test  = np.reshape(x_test,  (len(x_test),  200, 200, 1))\r\n",
    "    \r\n",
    "    # и массив кореженных тоже\r\n",
    "    # x_spoil =   x_spoil     [:len(x_train_spoiled)      //batch_size*batch_size]\r\n",
    "    vec_spoil = vec_spoil   [:len(x_train_vec_spoiled)  //batch_size*batch_size]\r\n",
    "    # x_spoil =   np.reshape(x_spoil,     (-1, batch_size, 200, 200, 1)) \r\n",
    "    vec_spoil = np.reshape(vec_spoil,   (-1, batch_size, 96)) \r\n",
    "\r\n",
    "    # print (f\"\\nvec shape {vec.shape}\")                  # (31, 256, 96)\r\n",
    "    # print (f\"vec_spoil shape {vec_spoil.shape}\")        # (31, 256, 96)\r\n",
    "    losses = [10e100] # потери\r\n",
    "    for epoch in range(1, epochs+1):\r\n",
    "        # print(f\"Epoch {epoch}\")\r\n",
    "        for i, _ in enumerate(vec):\r\n",
    "            # batch_x =           x[i]\r\n",
    "            # batch_x_spoil =     x_spoil[i]    \r\n",
    "            batch_vec =         vec[i] \r\n",
    "            batch_vec_spoiled = vec_spoil[i]\r\n",
    "\r\n",
    "            loss = denoiser_model.train_on_batch([batch_vec, batch_vec_spoiled], batch_vec)\r\n",
    "\r\n",
    "        # эпоха отучилась, построим что вышло.\r\n",
    "        n = 10\r\n",
    "        vecs = batch_vec                    # это последний батч в каждой эпохе.\r\n",
    "        # print (f\"1! vecs shape{vecs.shape}\") # shape - (256, 64)\r\n",
    "        noised_vecs = batch_vec_spoiled     \r\n",
    "        # а картинки не участвуют в учении, количество бачей у них при делении датасета на бачи\r\n",
    "        # с векторами разное, поэтому найти соответствующую картинку проблематично. \r\n",
    "        # noised_imgs = noiser.predict(imgs, batch_size=batch_size)\r\n",
    "\r\n",
    "        # задача в том, чтобы картинке сопоставить спойленую картинку ( это не сложно из сгенерированной \r\n",
    "        # выборки сделать), но потом предиктить для этой картинки вектора. и рисовать их на новой картинке \r\n",
    "        # средствами opencv \r\n",
    "        encoded_vecs = encoder.predict(noised_vecs[:n],  batch_size=n)\r\n",
    "        decoded_vecs = decoder.predict(encoded_vecs[:n], batch_size=n)\r\n",
    "\r\n",
    "        # формируем картинки из предсказанных векторов\r\n",
    "        vecs =              np.reshape(vecs,            (-1, 16, 6))\r\n",
    "        noised_vecs =       np.reshape(noised_vecs,     (-1, 16, 6))\r\n",
    "        predicted_vecs =    np.reshape(decoded_vecs,    (-1, 16, 6))\r\n",
    "        \r\n",
    "        # print (f\"vecs shape{vecs.shape} vecs[0] {vecs[0]}\")\r\n",
    "        \r\n",
    "        # imgs_fr_vec =           np.array([im for im in map(inst_.draw_3d, (noised_vecs,predicted_vecs) )])\r\n",
    "        # imgs_spoil_fr_vec =     np.array([im for im in map(inst_.draw_3d, noised_vecs)])\r\n",
    "        # imgs_fr_decoded_vec =   np.array([im for im in map(inst_.draw_3d, predicted_vecs)])\r\n",
    "\r\n",
    "        # print (f\"batch_x shape{     np.array(batch_x).shape}\")      # (256, 200, 200, 1)\r\n",
    "        # print (f\"imgs_fr_vec shape{ np.array(imgs_fr_vec).shape}\")  # (256, 200, 200)\r\n",
    "        if (epoch%200 ==0) or (epoch in [1,2, 10, 30, 80]):\r\n",
    "            print(f\"Epoch {epoch} loss -{loss}\")\r\n",
    "        # рисуем картинки и сохраняем модели\r\n",
    "        # if (epoch % 20 ==0) or (epoch in [1,2,3,5,10]):\r\n",
    "        # if (epoch % 200 ==0) or (epoch in [10, 30, 80]):\r\n",
    "        if (epoch % 200 ==0) and (epoch > 1000):\r\n",
    "            # print(f'Epoch {epoch}')\r\n",
    "            # plot_digits(batch_x[:n], batch_x_spoil[:n], imgs_fr_vec[:n], imgs_spoil_fr_vec[:n], imgs_fr_decoded_vec[:n])            \r\n",
    "            # plot_digits(imgs_fr_vec[:n][0], imgs_spoil_fr_vec[:n], imgs_fr_decoded_vec[:n])\r\n",
    "            ##########plot_digits(imgs_fr_vec[:n])\r\n",
    "            # plot_digits(batch_x[:n], batch_x_spoil[:n])\r\n",
    "            if loss < min(losses):\r\n",
    "                losses.append(loss)\r\n",
    "                # save only the best models\r\n",
    "                denoiser_model.save(f'models3D/denoiser{epoch}ep_loss__{loss:.3}__.h5')\r\n",
    "                decoder.save(f'models3D/decoder{epoch}ep_loss__{loss:.3}__.h5')\r\n",
    "                encoder.save(f'models3D/encoder{epoch}ep_loss__{loss:.3}__.h5')\r\n",
    "        \r\n",
    "train_on_batch(x_train_vec, x_train_vec_spoiled, batch_size=batch_size, epochs=20000)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 loss -4191.8955078125\n",
      "Epoch 2 loss -2926.989013671875\n",
      "Epoch 10 loss -2.6505441665649414\n",
      "Epoch 30 loss -0.0907314270734787\n",
      "Epoch 80 loss -0.07411859184503555\n",
      "Epoch 200 loss -0.062350623309612274\n",
      "Epoch 400 loss -0.05787942558526993\n",
      "Epoch 600 loss -0.046960871666669846\n",
      "Epoch 800 loss -0.045594073832035065\n",
      "Epoch 1000 loss -0.04529182240366936\n",
      "Epoch 1200 loss -0.046661846339702606\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 1400 loss -0.03993479907512665\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 1600 loss -0.0402851477265358\n",
      "Epoch 1800 loss -0.0402161180973053\n",
      "Epoch 2000 loss -0.04240381717681885\n",
      "Epoch 2200 loss -0.04063557833433151\n",
      "Epoch 2400 loss -0.04101504385471344\n",
      "Epoch 2600 loss -0.042272910475730896\n",
      "Epoch 2800 loss -0.039403460919857025\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 3000 loss -0.039863407611846924\n",
      "Epoch 3200 loss -0.03948039188981056\n",
      "Epoch 3400 loss -0.038855426013469696\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 3600 loss -0.03835449367761612\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 3800 loss -0.039333101361989975\n",
      "Epoch 4000 loss -0.037515632808208466\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 4200 loss -0.040841057896614075\n",
      "Epoch 4400 loss -0.03983033820986748\n",
      "Epoch 4600 loss -0.039293382316827774\n",
      "Epoch 4800 loss -0.03921335190534592\n",
      "Epoch 5000 loss -0.038417089730501175\n",
      "Epoch 5200 loss -0.03925562649965286\n",
      "Epoch 5400 loss -0.038674890995025635\n",
      "Epoch 5600 loss -0.04036562889814377\n",
      "Epoch 5800 loss -0.038271214812994\n",
      "Epoch 6000 loss -0.03879161179065704\n",
      "Epoch 6200 loss -0.038795992732048035\n",
      "Epoch 6400 loss -0.039566826075315475\n",
      "Epoch 6600 loss -0.03944215923547745\n",
      "Epoch 6800 loss -0.03879101946949959\n",
      "Epoch 7000 loss -0.03902285546064377\n",
      "Epoch 7200 loss -0.03888079524040222\n",
      "Epoch 7400 loss -0.039673298597335815\n",
      "Epoch 7600 loss -0.03948075696825981\n",
      "Epoch 7800 loss -0.03950072079896927\n",
      "Epoch 8000 loss -0.039403319358825684\n",
      "Epoch 8200 loss -0.04030720889568329\n",
      "Epoch 8400 loss -0.04011561721563339\n",
      "Epoch 8600 loss -0.03997982665896416\n",
      "Epoch 8800 loss -0.040033429861068726\n",
      "Epoch 9000 loss -0.04016784951090813\n",
      "Epoch 9200 loss -0.03988951817154884\n",
      "Epoch 9400 loss -0.03989565372467041\n",
      "Epoch 9600 loss -0.03990430012345314\n",
      "Epoch 9800 loss -0.041526392102241516\n",
      "Epoch 10000 loss -0.039985086768865585\n",
      "Epoch 10200 loss -0.04047074913978577\n",
      "Epoch 10400 loss -0.04209906607866287\n",
      "Epoch 10600 loss -0.04031166061758995\n",
      "Epoch 10800 loss -0.04174499958753586\n",
      "Epoch 11000 loss -0.04069183021783829\n",
      "Epoch 11200 loss -0.04035068303346634\n",
      "Epoch 11400 loss -0.04050023853778839\n",
      "Epoch 11600 loss -0.040777985006570816\n",
      "Epoch 11800 loss -0.041761916130781174\n",
      "Epoch 12000 loss -0.04106394946575165\n",
      "Epoch 12200 loss -0.04248544201254845\n",
      "Epoch 12400 loss -0.04134269058704376\n",
      "Epoch 12600 loss -0.04150843620300293\n",
      "Epoch 12800 loss -0.041470058262348175\n",
      "Epoch 13000 loss -0.041223347187042236\n",
      "Epoch 13200 loss -0.04136456549167633\n",
      "Epoch 13400 loss -0.04243188723921776\n",
      "Epoch 13600 loss -0.04136013239622116\n",
      "Epoch 13800 loss -0.042793359607458115\n",
      "Epoch 14000 loss -0.0415349155664444\n",
      "Epoch 14200 loss -0.04255115985870361\n",
      "Epoch 14400 loss -0.04174176976084709\n",
      "Epoch 14600 loss -0.042142778635025024\n",
      "Epoch 14800 loss -0.041937489062547684\n",
      "Epoch 15000 loss -0.04186875373125076\n",
      "Epoch 15200 loss -0.042265161871910095\n",
      "Epoch 15400 loss -0.04250074550509453\n",
      "Epoch 15600 loss -0.041962433606386185\n",
      "Epoch 15800 loss -0.04230986535549164\n",
      "Epoch 16000 loss -0.042761579155921936\n",
      "Epoch 16200 loss -0.04310339316725731\n",
      "Epoch 16400 loss -0.04250188544392586\n",
      "Epoch 16600 loss -0.04354022443294525\n",
      "Epoch 16800 loss -0.0427522286772728\n",
      "Epoch 17000 loss -0.04248400032520294\n",
      "Epoch 17200 loss -0.04298675060272217\n",
      "Epoch 17400 loss -0.042465776205062866\n",
      "Epoch 17600 loss -0.04270903021097183\n",
      "Epoch 17800 loss -0.0428677573800087\n",
      "Epoch 18000 loss -0.042646508663892746\n",
      "Epoch 18200 loss -0.04318122938275337\n",
      "Epoch 18400 loss -0.04320452734827995\n",
      "Epoch 18600 loss -0.04270261898636818\n",
      "Epoch 18800 loss -0.04305797442793846\n",
      "Epoch 19000 loss -0.04296368733048439\n",
      "Epoch 19200 loss -0.04311307147145271\n",
      "Epoch 19400 loss -0.04355306923389435\n",
      "Epoch 19600 loss -0.0429002046585083\n",
      "Epoch 19800 loss -0.043517112731933594\n",
      "Epoch 20000 loss -0.04305722564458847\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# c_autoencoder.save(f'models/c_autoencoder.h5'\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "encoded_imgs[:20]"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit"
  },
  "interpreter": {
   "hash": "04635d289a519a1410467dd0afb0db42f9184808881ca68b2eb5a687a20a5a94"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}