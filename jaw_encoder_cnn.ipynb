{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "энкодер- декодер на основе сверточной сети. надо сделать не fit модели а train step."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# from keras.datasets import mnist\r\n",
    "import numpy as np\r\n",
    "# from jaw_gen import *\r\n",
    "import tensorflow\r\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape\r\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\r\n",
    "from tensorflow.keras.models import Model\r\n",
    "\r\n",
    "import tensorflow.keras.backend as K\r\n",
    "from tensorflow.keras.layers import Lambda\r\n",
    "import cv2\r\n",
    "\r\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import keras\r\n",
    "print (f\"keras ver.{tensorflow.keras.__version__}\")\r\n",
    "# print (f\"keras ver.{1}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# класс который генерит картинки размерностью с искривлениями зубов или без.\r\n",
    "\r\n",
    "# print(f\" cv2 ver. {cv2.__version__}, np ver. {np.__version__}\")\r\n",
    "np.random.seed() # устанавливает режим случайных чисел без повторений от запуска к запуску\r\n",
    "\r\n",
    "class Landmark_gen():\r\n",
    "    ''' creates pictures with incistor edges landmarks '''\r\n",
    "\r\n",
    "    def __init__(self, number=100, dim=(200, 200)):\r\n",
    "        self.number = number\r\n",
    "        self.dim = dim\r\n",
    "\r\n",
    "    def image_gen(  self, \r\n",
    "                    name='_', \r\n",
    "                    scale1=1, \r\n",
    "                    factor=2.6, \r\n",
    "                    shift_x=0, \r\n",
    "                    shift_y=0, \r\n",
    "                    spoiled = False,    # вводит хаотичный наклон и смещение зубов имитируя T1\r\n",
    "                    shiftX = False,     # add random shift for whole tooth for X axis\r\n",
    "                    shiftY = False,     # add random shift for whole tooth for Y axis\r\n",
    "                    show=False):\r\n",
    "        # встроить сюда еще смещение \r\n",
    "        # все делаем под разрешение 200x200 \r\n",
    "        self.back = np.zeros((200, 200))            # картинка с ровными зубами\r\n",
    "        self.back_spoiled = np.zeros((200,200))     # картинка с корявыми зубами\r\n",
    "        self.factor = factor\r\n",
    "        center = (100, 100)\r\n",
    "\r\n",
    "        # оси координат по центру\r\n",
    "        if 1:\r\n",
    "            cv2.line(self.back, (0, center[1]), (200, center[1]), 0.4, 1)\r\n",
    "            cv2.line(self.back, (center[0], 0), (center[0], 200), 0.4, 1)\r\n",
    "            cv2.line(self.back_spoiled, (0, center[1]), (200, center[1]), 0.4, 1)\r\n",
    "            cv2.line(self.back_spoiled, (center[0], 0), (center[0], 200), 0.4, 1)\r\n",
    "\r\n",
    "        # строим дугу. так чтобы на основе ее точек можно было зубья подровнять\r\n",
    "        for i in range(-8, 8):\r\n",
    "            # строим точки графика\r\n",
    "            # первая точка зуба\r\n",
    "            point_ = [int(i*scale1)+center[0], int(self.duga(i)) + center[1]]\r\n",
    "            # вторая\r\n",
    "            point2_ = [int((i+1-0.2)*scale1 +\r\n",
    "                          center[0]), int(self.duga(i+1-0.2)) + center[1]]\r\n",
    "            \r\n",
    "            # строим линии по дуге - ровные зубы\r\n",
    "            cv2.line(self.back, point_, point2_, 1, 2)\r\n",
    "\r\n",
    "            # шатаем зубы если задано шатать и выдаем на картинку back_spoiled\r\n",
    "            if spoiled: \r\n",
    "                if i in [-8, -7, -6, 5, 6, 7 ]: # портим моляры \r\n",
    "                    point_[0]+= int((np.random.sample()-1)*i)\r\n",
    "\r\n",
    "                if i in [-5, -4, -3, -2, 1, 2, 3, 4]: # премоляры и резцы\r\n",
    "                    point_[1]+= int((np.random.sample()-1)*i*2)\r\n",
    "\r\n",
    "                if i in [-1, 0]: # передние резцы\r\n",
    "                    point_[1]+= int((np.random.sample()-1)*4)\r\n",
    "            \r\n",
    "            if shiftX:\r\n",
    "                case_shift_x_ = int((np.random.sample()-1)*5)\r\n",
    "                point_[0] += case_shift_x_\r\n",
    "                point2_[0] += case_shift_x_\r\n",
    "            \r\n",
    "            if shiftY:\r\n",
    "                case_shift_y_ = int((np.random.sample()-1)*5)\r\n",
    "                point_[1] += case_shift_y_\r\n",
    "                point2_[1] += case_shift_y_\r\n",
    "            \r\n",
    "            # для второй картинки сторим покореженные зубы. или те-же если корежить не надо\r\n",
    "            cv2.line(self.back_spoiled, point_, point2_, 1, 2)\r\n",
    "            \r\n",
    "            # cv2.circle(self.back, point_, 1, 0.2, 1)\r\n",
    "        # print (f\"self.back shape {self.back.shape}\")\r\n",
    "\r\n",
    "        if show: # shows picture. beware using in batсh processing\r\n",
    "            self.back = cv2.resize(self.back, self.dim)  # увеличиваем только для показа\r\n",
    "            self.back_spoiled = cv2.resize(self.back_spoiled, self.dim)  # увеличиваем только для показа\r\n",
    "            img_for_show = np.hstack((self.back, self.back_spoiled))\r\n",
    "            cv2.imshow(name, img_for_show)\r\n",
    "            k = cv2.waitKey()\r\n",
    "\r\n",
    "        return self.back, self.back_spoiled  \r\n",
    "\r\n",
    "    def duga(self, x):\r\n",
    "        ''' returns arc function'''\r\n",
    "        return abs(x)**self.factor - 200 * 0.35"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# готовим входные данные\r\n",
    "inst_ = Landmark_gen()\r\n",
    "data_len = 10000\r\n",
    "dataset = []\r\n",
    "dataset_spoiled = []\r\n",
    "\r\n",
    "for i in range(data_len):\r\n",
    "    scale =  9 + np.random.sample()*3     # это для размера 200, диапазон от 14 до 19 для размера 400\r\n",
    "    factor = 2.2 + np.random.sample()/4   # это для размера 200, диапазон 2.5 - 2.7 для размера 400 \r\n",
    "    # name = f\"scale {scale:.4}  factor {factor:.3}\"\r\n",
    "    img_, img_spoiled_ = inst_.image_gen(scale1=scale, factor=factor, spoiled=True, shiftX=True, shift_y=True)\r\n",
    "    dataset.append(img_)\r\n",
    "    dataset_spoiled.append(img_spoiled_)\r\n",
    "\r\n",
    "\r\n",
    "set_divider_ = round(data_len*0.8)\r\n",
    "# print (f\"set_divider_ {set_divider_}\")\r\n",
    "\r\n",
    "x_train = dataset[:set_divider_]\r\n",
    "x_test = dataset[set_divider_:]\r\n",
    "# print (f\"length {len(x_train)} - {len(x_test)}\")\r\n",
    "\r\n",
    "x_train_spoiled = dataset_spoiled[:set_divider_]\r\n",
    "x_test_spoiled = dataset_spoiled[set_divider_:]\r\n",
    "\r\n",
    "# конвертнем данные\r\n",
    "x_train = np.array(x_train, dtype=\"float32\")    # x_train = x_train.astype('float32') / 255. \r\n",
    "x_test  = np.array(x_test, dtype=\"float32\")      # x_test  = x_test .astype('float32') / 255.\r\n",
    "x_train = np.reshape(x_train, (len(x_train), 200, 200, 1))\r\n",
    "x_test  = np.reshape(x_test,  (len(x_test),  200, 200, 1))\r\n",
    "\r\n",
    "x_train_spoiled = np.array(x_train_spoiled, dtype=\"float32\")   \r\n",
    "x_test_spoiled  = np.array(x_test_spoiled, dtype=\"float32\")    \r\n",
    "x_train_spoiled = np.reshape(x_train_spoiled, (len(x_train_spoiled), 200, 200, 1))\r\n",
    "x_test_spoiled  = np.reshape(x_test_spoiled,  (len(x_test_spoiled),  200, 200, 1))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def create_deep_conv_ae():\r\n",
    "    input_img = Input(shape=(200, 200, 1))\r\n",
    "\r\n",
    "    x = Conv2D(128, (7, 7), activation='relu', padding='same')(input_img)\r\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\r\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\r\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\r\n",
    "    encoded = Conv2D(1, (3, 3), activation='relu', padding='same')(x) # в оригинале тут оставался один фильтр. \r\n",
    "\r\n",
    "    # На этом моменте представление  (50, 50, 8) т.е. 20000-размерное нихера сибе. посмотрим как будет учиться Уже нет. уже (50, 50, 1)\r\n",
    "\r\n",
    "    input_encoded = Input(shape=(50, 50, 1))\r\n",
    "    x = Conv2D(32, (7, 7), activation='relu', padding='same')(input_encoded)\r\n",
    "    x = UpSampling2D((2, 2))(x)\r\n",
    "    x = Conv2D(128, (2, 2), activation='relu', padding='same')(x)\r\n",
    "    x = UpSampling2D((2, 2))(x)\r\n",
    "    decoded = Conv2D(1, (7, 7), activation='sigmoid', padding='same')(x)\r\n",
    "\r\n",
    "    # Модели\r\n",
    "    encoder = Model(input_img, encoded, name=\"encoder\")\r\n",
    "    decoder = Model(input_encoded, decoded, name=\"decoder\")\r\n",
    "    autoencoder = Model(input_img, decoder(encoder(input_img)), name=\"autoencoder\")\r\n",
    "    return encoder, decoder, autoencoder\r\n",
    "\r\n",
    "c_encoder, c_decoder, c_autoencoder = create_deep_conv_ae()\r\n",
    "c_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\r\n",
    "\r\n",
    "# c_autoencoder.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch_size = 16\r\n",
    "\r\n",
    "def create_denoising_model(autoencoder):\r\n",
    "    def add_noise(x):\r\n",
    "        noise_factor = 0.5\r\n",
    "        # x = x + K.random_normal(x.get_shape(), 0.5, noise_factor) # не шумим. тсс...\r\n",
    "        x = K.clip(x, 0., 1.)\r\n",
    "        return x\r\n",
    "\r\n",
    "    input_img  = Input(batch_shape=(batch_size, 200, 200, 1))\r\n",
    "    input_img_spoiled  = Input(batch_shape=(batch_size, 200, 200, 1)) # вход для кореженных зубьев\r\n",
    "\r\n",
    "    # noised_img = Lambda(add_noise)(input_img) # больше не нужен шум\r\n",
    "\r\n",
    "    # noiser = Model(input_img, noised_img, name=\"noiser\") # и моделька шумелка не нужна\r\n",
    "    # denoiser_model = Model(input_img, autoencoder(noiser(input_img)), name=\"denoiser\") # это старая оригинальная модель\r\n",
    "    denoiser_model = Model([input_img, input_img_spoiled], autoencoder(input_img_spoiled), name=\"denoiser\")\r\n",
    "    # return noiser, denoiser_model\r\n",
    "    return denoiser_model\r\n",
    "\r\n",
    "\r\n",
    "# noiser, denoiser_model = create_denoising_model(c_autoencoder)\r\n",
    "denoiser_model = create_denoising_model(c_autoencoder)\r\n",
    "denoiser_model.compile(optimizer='adam', loss='binary_crossentropy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib inline\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "def plot_digits(*args):\r\n",
    "    args = [x.squeeze() for x in args]\r\n",
    "    n = min([x.shape[0] for x in args])\r\n",
    "    \r\n",
    "    plt.figure(figsize=(2*n, 2*len(args)))\r\n",
    "    for j in range(n):\r\n",
    "            for i in range(len(args)):\r\n",
    "                ax = plt.subplot(len(args), n, i*n + j + 1)\r\n",
    "                plt.imshow(args[i][j])\r\n",
    "                plt.gray()\r\n",
    "                ax.get_xaxis().set_visible(False)\r\n",
    "                ax.get_yaxis().set_visible(False)\r\n",
    "\r\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# вместо фита будем делать  model.train_on_batch читобы смотреть как учится и куда движемся\r\n",
    "def train_on_batch(x, x_spoil, batch_size=batch_size, epochs=100):\r\n",
    "    # подровняем массив обучащих так чтоб np.reshape не ругался на несовпадение размерности\r\n",
    "    x = x[:len(x_train)//batch_size*batch_size]\r\n",
    "    x = np.reshape(x, (-1, batch_size, 200, 200, 1)) # x_test  = np.reshape(x_test,  (len(x_test),  200, 200, 1))\r\n",
    "    \r\n",
    "    # и массив кореженных тоже\r\n",
    "    x_spoil = x_spoil[:len(x_train_spoiled)//batch_size*batch_size]\r\n",
    "    x_spoil = np.reshape(x_spoil, (-1, batch_size, 200, 200, 1)) \r\n",
    "    \r\n",
    "    for epoch in range(1, epochs+1):\r\n",
    "        print(f\"Epoch {epoch}\")\r\n",
    "        for i, _ in enumerate(tqdm(x)):\r\n",
    "            batch_x = x[i]\r\n",
    "            batch_x_spoiled = x_spoil[i]\r\n",
    "            denoiser_model.train_on_batch([batch_x, batch_x_spoiled], batch_x)\r\n",
    "\r\n",
    "        # эпоха отучилась, построим что вышло.\r\n",
    "        n = 10\r\n",
    "        imgs = batch_x\r\n",
    "        # noised_imgs = noiser.predict(imgs, batch_size=batch_size)\r\n",
    "        noised_imgs = batch_x_spoiled\r\n",
    "        encoded_imgs = c_encoder.predict(noised_imgs[:n],  batch_size=n)\r\n",
    "        decoded_imgs = c_decoder.predict(encoded_imgs[:n], batch_size=n)\r\n",
    "\r\n",
    "        # рисуем картинки и сохраняем модели\r\n",
    "        if (epoch % 20 ==0) or (epoch in [1,2,3,5,10]):\r\n",
    "            plot_digits(imgs[:n], noised_imgs, decoded_imgs)\r\n",
    "            denoiser_model.save(f'models/denoiser_1_flt_{epoch}ep.h5')\r\n",
    "            c_decoder.save(f'models/c_decoder_1_flt_{epoch}ep.h5')\r\n",
    "            c_encoder.save(f'models/c_encoder_1_flt_{epoch}ep.h5')\r\n",
    "        \r\n",
    "# train_on_batch(x_train, batch_size=batch_size, epochs=100)\r\n",
    "train_on_batch(x_train, x_train_spoiled, batch_size=batch_size, epochs=100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "c_autoencoder.save(f'models/c_autoencoder.h5')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "n = 10\r\n",
    "\r\n",
    "imgs = x_test[:batch_size]\r\n",
    "noised_imgs = noiser.predict(imgs, batch_size=batch_size)\r\n",
    "encoded_imgs = с_encoder.predict(noised_imgs[:n],  batch_size=n)\r\n",
    "decoded_imgs = с_decoder.predict(encoded_imgs[:n], batch_size=n)\r\n",
    "\r\n",
    "plot_digits(imgs[:n], noised_imgs, decoded_imgs)\r\n",
    "# plot_digits(imgs[:n], decoded_imgs)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "encoded_imgs[:20]"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit"
  },
  "interpreter": {
   "hash": "04635d289a519a1410467dd0afb0db42f9184808881ca68b2eb5a687a20a5a94"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}