{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "3D энкодер- декодер. Отличие от предыдущей версии - вместо растра точек на вход сети подать вектора лендмарков в виде набора координат и длин."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# from keras.datasets import mnist\r\n",
    "import numpy as np\r\n",
    "# from jaw_gen import *\r\n",
    "import tensorflow as tf \r\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Dropout\r\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization\r\n",
    "from tensorflow.keras.models import Model\r\n",
    "from tensorflow.keras.optimizers import Adam\r\n",
    "\r\n",
    "import tensorflow.keras.backend as K\r\n",
    "from tensorflow.keras.layers import Lambda\r\n",
    "import cv2\r\n",
    "\r\n",
    "from tqdm import tqdm\r\n",
    "# основное отличие - Landmark_gen больше не генерит картинки. только вектора. \r\n",
    "# и у него теперь есть 3D рисовалка, которая есть независимый метод\r\n",
    "from jaw_gen3d import Landmark_gen "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# готовим входные данные\r\n",
    "inst_ =                 Landmark_gen()\r\n",
    "data_len =              10000\r\n",
    "dataset =               []\r\n",
    "dataset_spoiled =       []\r\n",
    "dataset_vec =           []\r\n",
    "dataset_vec_spoiled =   []\r\n",
    "\r\n",
    "for i in range(data_len):\r\n",
    "    scale =  9 + np.random.sample()*3     # это для размера 200, диапазон от 14 до 19 для размера 400\r\n",
    "    factor = 2.2 + np.random.sample()/4   # это для размера 200, диапазон 2.5 - 2.7 для размера 400 \r\n",
    "    # name = f\"scale {scale:.4}  factor {factor:.3}\"\r\n",
    "    vec, vec_spoiled = inst_.image_gen(scale=scale, factor=factor, spoiled=True, shiftX=True, shiftY=True)\r\n",
    "    # dataset.append(img_)\r\n",
    "    # dataset_spoiled.append(img_spoiled_)\r\n",
    "\r\n",
    "    # собираем датасет из векторов \r\n",
    "    dataset_vec.append(vec)\r\n",
    "    dataset_vec_spoiled.append(vec_spoiled)\r\n",
    "# print (f\"dataset_vec {dataset_vec[:1]}\")\r\n",
    "print (f\"dataset_vec len {len(dataset_vec)} \")\r\n",
    "print (f\"dataset_vec_spoiled len {len(dataset_vec_spoiled)} \")\r\n",
    "\r\n",
    "# преобразуем датасет в numpy массив\r\n",
    "# dataset =               np.array(dataset,               dtype=\"float32\")    # x_train = x_train.astype('float32') / 255. \r\n",
    "# dataset_spoiled =       np.array(dataset_spoiled,       dtype=\"float32\") \r\n",
    "dataset_vec =           np.array(dataset_vec,           dtype=\"float32\") \r\n",
    "dataset_vec_spoiled =   np.array(dataset_vec_spoiled,   dtype=\"float32\") \r\n",
    "\r\n",
    "# dataset =           np.reshape(dataset,         (len(dataset), 200, 200, 1))\r\n",
    "# dataset_spoiled =   np.reshape(dataset_spoiled, (len(dataset_spoiled), 200, 200, 1))\r\n",
    "\r\n",
    "# разобьем датасет на тренировочную и тестовую части\r\n",
    "set_divider_ = round(data_len*0.8)\r\n",
    "# print (f\"set_divider_ {set_divider_}\")\r\n",
    "\r\n",
    "# x_train = dataset[:set_divider_]\r\n",
    "# x_test = dataset[set_divider_:]\r\n",
    "# print (f\"length {len(x_train)} - {len(x_test)}\")\r\n",
    "\r\n",
    "# x_train_spoiled = dataset_spoiled[:set_divider_]\r\n",
    "# x_test_spoiled = dataset_spoiled[set_divider_:]\r\n",
    "\r\n",
    "# векторный датасет\r\n",
    "x_train_vec =   dataset_vec[:set_divider_]\r\n",
    "x_test_vec =    dataset_vec[set_divider_:]\r\n",
    "# print (f\"length vec {len(x_train_vec)} - {len(x_test_vec)}\")\r\n",
    "\r\n",
    "x_train_vec_spoiled =   dataset_vec_spoiled[:set_divider_]\r\n",
    "x_test_vec_spoiled =    dataset_vec_spoiled[set_divider_:]\r\n",
    "# print (f\"vec [0]{x_test_vec[0]}\")\r\n",
    "print (f\"length vec         {len(x_train_vec)} - {len(x_test_vec)}\")\r\n",
    "print (f\"length vec spoil   {len(x_train_vec_spoiled)} - {len(x_test_vec_spoiled)}\")\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dataset_vec len 10000 \n",
      "dataset_vec_spoiled len 10000 \n",
      "length vec         8000 - 2000\n",
      "length vec spoil   8000 - 2000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def create_vec_ae3D():\r\n",
    "    # 3d кодер - декодер содержит на входе 6*16=96 значений.\r\n",
    "    dim_code = 16 # размерность кодированного слоя\r\n",
    "    activation = 'elu' \r\n",
    "    # activation = 'linear'\r\n",
    "    inputs = Input(96,)\r\n",
    "    WITH_BN = True # go with batcNormalization\r\n",
    "\r\n",
    "    # encoder\r\n",
    "    x = Dense(96, activation=activation)(inputs)\r\n",
    "    x= BatchNormalization()(x)      if WITH_BN else x\r\n",
    "    x = Dense(96, activation=activation)(x)\r\n",
    "    x= BatchNormalization()(x)      if WITH_BN else x\r\n",
    "    code = Dense(dim_code, activation='linear')(x)\r\n",
    "\r\n",
    "    # decoder\r\n",
    "    input_encoded = Input((dim_code,))\r\n",
    "    x = Dense(dim_code, activation=activation)(input_encoded)\r\n",
    "    x= BatchNormalization()(x)      if WITH_BN else x\r\n",
    "    x = Dense(96, activation=activation)(x)\r\n",
    "    x= BatchNormalization()(x)      if WITH_BN else x\r\n",
    "    out = Dense(96, activation='linear')(x)\r\n",
    "    \r\n",
    "    # Модели\r\n",
    "    encoder = Model(inputs, code, name=\"encoder\")\r\n",
    "    decoder = Model(input_encoded, out, name=\"decoder\")\r\n",
    "    autoencoder = Model(inputs, decoder(encoder(inputs)), name=\"autoencoder\")\r\n",
    "    return encoder, decoder, autoencoder\r\n",
    "\r\n",
    "encoder, decoder, autoencoder = create_vec_ae3D()\r\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\r\n",
    "# autoencoder.compile(Adam(0.003), 'mse')\r\n",
    "\r\n",
    "# c_autoencoder.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "batch_size = 256\r\n",
    "\r\n",
    "def create_denoising_model(autoencoder):\r\n",
    "    \r\n",
    "    inputs  = Input(batch_shape=(batch_size, 96))\r\n",
    "    inputs_spoiled  = Input(batch_shape=(batch_size, 96)) # вход для кореженных зубьев\r\n",
    "\r\n",
    "    denoiser_model = Model([inputs, inputs_spoiled], autoencoder(inputs_spoiled), name=\"denoiser\")\r\n",
    "    # return noiser, denoiser_model\r\n",
    "    return denoiser_model\r\n",
    "\r\n",
    "\r\n",
    "# noiser, denoiser_model = create_denoising_model(c_autoencoder)\r\n",
    "denoiser_model = create_denoising_model(autoencoder)\r\n",
    "denoiser_model.compile(optimizer='adam', loss='mean_squared_error')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "%matplotlib inline\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "def plot_digits(*args):\r\n",
    "    # for a in args:\r\n",
    "        # print (f\"type args {type(a)}\")\r\n",
    "    args = [x.squeeze() for x in args]\r\n",
    "    n = min([x.shape[0] for x in args])\r\n",
    "    \r\n",
    "    plt.figure(figsize=(2*n, 2*len(args)))\r\n",
    "    for j in range(n):\r\n",
    "            for i in range(len(args)):\r\n",
    "                ax = plt.subplot(len(args), n, i*n + j + 1)\r\n",
    "                plt.imshow(args[i][j])\r\n",
    "                plt.gray()\r\n",
    "                ax.get_xaxis().set_visible(False)\r\n",
    "                ax.get_yaxis().set_visible(False)\r\n",
    "\r\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "%matplotlib inline\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "def plot_3d(*args):\r\n",
    "    # \r\n",
    "    n = min([x.shape[0] for x in args]) # сколько столбцов\r\n",
    "    plt.figure(figsize=(2*n, 2*len(args)))\r\n",
    "    for j in range(n):\r\n",
    "        for i in range(len(args)):\r\n",
    "            pass #ax = plt.\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# вместо фита будем делать  model.train_on_batch читобы смотреть как учится и куда движемся\r\n",
    "def train_on_batch(vec, vec_spoil, batch_size=batch_size, epochs=100):\r\n",
    "    # подровняем массив картинок и обучающих векторов так, чтоб np.reshape не ругался - на несовпадение размерности\r\n",
    "    # сделаем его длину кратной размеру батча\r\n",
    "    # print (f\"x_train_vec.shape {x_train_vec.shape}\")    # (8000, 16, 6)\r\n",
    "    # print (f\"vec shape {vec.shape}\")                    # (8000, 16, 6)\r\n",
    "    # print (f\"vec_spoil shape {vec_spoil.shape}\")        # (8000, 16, 6)\r\n",
    "\r\n",
    "    # x =     x   [:len(x_train)//    batch_size*batch_size]\r\n",
    "    vec =   vec [:len(x_train_vec)//batch_size*batch_size]\r\n",
    "    # x =     np.reshape(x,   (-1, batch_size, 200, 200, 1))  # x_test  = np.reshape(x_test,  (len(x_test),  200, 200, 1))\r\n",
    "    vec =   np.reshape(vec, (-1, batch_size, 96))           # x_test  = np.reshape(x_test,  (len(x_test),  200, 200, 1))\r\n",
    "    \r\n",
    "    # и массив кореженных тоже\r\n",
    "    # x_spoil =   x_spoil     [:len(x_train_spoiled)      //batch_size*batch_size]\r\n",
    "    vec_spoil = vec_spoil   [:len(x_train_vec_spoiled)  //batch_size*batch_size]\r\n",
    "    # x_spoil =   np.reshape(x_spoil,     (-1, batch_size, 200, 200, 1)) \r\n",
    "    vec_spoil = np.reshape(vec_spoil,   (-1, batch_size, 96)) \r\n",
    "\r\n",
    "    # print (f\"\\nvec shape {vec.shape}\")                  # (31, 256, 96)\r\n",
    "    # print (f\"vec_spoil shape {vec_spoil.shape}\")        # (31, 256, 96)\r\n",
    "    \r\n",
    "    for epoch in range(1, epochs+1):\r\n",
    "        # print(f\"Epoch {epoch}\")\r\n",
    "        for i, _ in enumerate(vec):\r\n",
    "            # batch_x =           x[i]\r\n",
    "            # batch_x_spoil =     x_spoil[i]    \r\n",
    "            batch_vec =         vec[i] \r\n",
    "            batch_vec_spoiled = vec_spoil[i]\r\n",
    "\r\n",
    "            loss = denoiser_model.train_on_batch([batch_vec, batch_vec_spoiled], batch_vec)\r\n",
    "\r\n",
    "        # эпоха отучилась, построим что вышло.\r\n",
    "        n = 10\r\n",
    "        vecs = batch_vec                    # это последний батч в каждой эпохе.\r\n",
    "        # print (f\"1! vecs shape{vecs.shape}\") # shape - (256, 64)\r\n",
    "        noised_vecs = batch_vec_spoiled     \r\n",
    "        # а картинки не участвуют в учении, количество бачей у них при делении датасета на бачи\r\n",
    "        # с векторами разное, поэтому найти соответствующую картинку проблематично. \r\n",
    "        # noised_imgs = noiser.predict(imgs, batch_size=batch_size)\r\n",
    "\r\n",
    "        # задача в том, чтобы картинке сопоставить спойленую картинку ( это не сложно из сгенерированной \r\n",
    "        # выборки сделать), но потом предиктить для этой картинки вектора. и рисовать их на новой картинке \r\n",
    "        # средствами opencv \r\n",
    "        encoded_vecs = encoder.predict(noised_vecs[:n],  batch_size=n)\r\n",
    "        decoded_vecs = decoder.predict(encoded_vecs[:n], batch_size=n)\r\n",
    "\r\n",
    "        # формируем картинки из предсказанных векторов\r\n",
    "        vecs =              np.reshape(vecs,            (-1, 16, 6))\r\n",
    "        noised_vecs =       np.reshape(noised_vecs,     (-1, 16, 6))\r\n",
    "        predicted_vecs =    np.reshape(decoded_vecs,    (-1, 16, 6))\r\n",
    "        \r\n",
    "        # print (f\"vecs shape{vecs.shape} vecs[0] {vecs[0]}\")\r\n",
    "        \r\n",
    "        # imgs_fr_vec =           np.array([im for im in map(inst_.draw_3d, (noised_vecs,predicted_vecs) )])\r\n",
    "        # imgs_spoil_fr_vec =     np.array([im for im in map(inst_.draw_3d, noised_vecs)])\r\n",
    "        # imgs_fr_decoded_vec =   np.array([im for im in map(inst_.draw_3d, predicted_vecs)])\r\n",
    "\r\n",
    "        # print (f\"batch_x shape{     np.array(batch_x).shape}\")      # (256, 200, 200, 1)\r\n",
    "        # print (f\"imgs_fr_vec shape{ np.array(imgs_fr_vec).shape}\")  # (256, 200, 200)\r\n",
    "        if (epoch%200 ==0) or (epoch in [1,2, 10, 30, 80]):\r\n",
    "            print(f\"Epoch {epoch} loss -{loss}\")\r\n",
    "        # рисуем картинки и сохраняем модели\r\n",
    "        # if (epoch % 20 ==0) or (epoch in [1,2,3,5,10]):\r\n",
    "        # if (epoch % 200 ==0) or (epoch in [10, 30, 80]):\r\n",
    "        if (epoch % 200 ==0):\r\n",
    "            # print(f'Epoch {epoch}')\r\n",
    "            # plot_digits(batch_x[:n], batch_x_spoil[:n], imgs_fr_vec[:n], imgs_spoil_fr_vec[:n], imgs_fr_decoded_vec[:n])            \r\n",
    "            # plot_digits(imgs_fr_vec[:n][0], imgs_spoil_fr_vec[:n], imgs_fr_decoded_vec[:n])\r\n",
    "            ##########plot_digits(imgs_fr_vec[:n])\r\n",
    "            # plot_digits(batch_x[:n], batch_x_spoil[:n])\r\n",
    "            denoiser_model.save(f'models3D/denoiser{epoch}ep_loss{loss:.5}.h5')\r\n",
    "            decoder.save(f'models3D/decoder{epoch}ep_loss{loss:.5}.h5')\r\n",
    "            encoder.save(f'models3D/encoder{epoch}ep_loss{loss:.5}.h5')\r\n",
    "        \r\n",
    "train_on_batch(x_train_vec, x_train_vec_spoiled, batch_size=batch_size, epochs=5000)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 loss -4627.6396484375\n",
      "Epoch 2 loss -4586.8974609375\n",
      "Epoch 10 loss -2954.6708984375\n",
      "Epoch 30 loss -105.96754455566406\n",
      "Epoch 80 loss -0.19330239295959473\n",
      "Epoch 200 loss -0.1341981291770935\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 400 loss -0.12341070175170898\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 600 loss -0.10837530344724655\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 800 loss -0.10830500721931458\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 1000 loss -0.09967564791440964\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 1200 loss -0.1062750369310379\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 1400 loss -0.1045525074005127\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# c_autoencoder.save(f'models/c_autoencoder.h5'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib inline\r\n",
    "import numpy as np\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "\r\n",
    "# x = np.linspace(0, 3*np.pi, 500)\r\n",
    "# plt.plot(x, np.sin(x**2))\r\n",
    "fig = plt.figure()\r\n",
    "ax = fig.add_subplot(projection='3d')\r\n",
    "# x = np.array([0,2])#np.sin(theta)\r\n",
    "teeth = [[[2,3],[3,4],[4,1]], [[3,1], [2,5],[3,7]]]\r\n",
    "colors =['r', 'g', 'b']\r\n",
    "for ind, t in enumerate(teeth):\r\n",
    "    x = t[0]\r\n",
    "    y = t[1]\r\n",
    "    z = t[2]\r\n",
    "    ax.plot(x, y, z, label='xo', color = colors[ind])\r\n",
    "plt.title('A simple chirp')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "encoded_imgs[:20]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit"
  },
  "interpreter": {
   "hash": "04635d289a519a1410467dd0afb0db42f9184808881ca68b2eb5a687a20a5a94"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}