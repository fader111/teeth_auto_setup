{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization, Reshape, Flatten, RepeatVector\n",
    "from tensorflow.keras.layers import Lambda, Dense, Input, Conv2D, MaxPool2D, UpSampling2D, concatenate\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.models import Model, load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Регистрация сессии в keras\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "# sess = tf.Session()\n",
    "# K.set_session(sess)\n",
    "\n",
    "\n",
    "# Импорт датасета\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test  = x_test .astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test  = np.reshape(x_test,  (len(x_test),  28, 28, 1))\n",
    "\n",
    "y_train_cat = to_categorical(y_train).astype(np.float32)\n",
    "y_test_cat  = to_categorical(y_test).astype(np.float32)\n",
    "\n",
    "\n",
    "# Глобальные константы\n",
    "batch_size = 64\n",
    "batch_shape = (batch_size, 28, 28, 1)\n",
    "latent_dim = 8\n",
    "num_classes = 10\n",
    "dropout_rate = 0.3\n",
    "gamma = 1 # Коэффициент гамма\n",
    "\n",
    "\n",
    "# Итераторы тренировочных и тестовых батчей\n",
    "def gen_batch(x, y):\n",
    "    n_batches = x.shape[0] // batch_size\n",
    "    while(True):\n",
    "        idxs = np.random.permutation(y.shape[0])\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]\n",
    "        for i in range(n_batches):\n",
    "            yield x[batch_size*i: batch_size*(i+1)], y[batch_size*i: batch_size*(i+1)]\n",
    "\n",
    "train_batches_it = gen_batch(x_train, y_train_cat)\n",
    "test_batches_it  = gen_batch(x_test,  y_test_cat)\n",
    "\n",
    "\n",
    "# Входные плейсхолдеры\n",
    "img = Input(shape=(None, 28, 28, 1),  name='image')\n",
    "lbl = Input(shape=(None, 10),         name='labels')\n",
    "z   = Input(shape=(None, latent_dim), name='z')\n",
    "\n",
    "# img = Input(tensor=x_)\n",
    "# lbl = Input(tensor=y_)\n",
    "# z   = Input(tensor=z_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'variable_scope'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12984/771672600.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'encoder'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_bn_relu_and_dropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'variable_scope'"
     ]
    }
   ],
   "source": [
    "def add_units_to_conv2d(conv2, units):\n",
    "    dim1 = int(conv2.shape[1])\n",
    "    dim2 = int(conv2.shape[2])\n",
    "    dimc = int(units.shape[1])\n",
    "    repeat_n = dim1*dim2\n",
    "    units_repeat = RepeatVector(repeat_n)(lbl)\n",
    "    units_repeat = Reshape((dim1, dim2, dimc))(units_repeat)\n",
    "    return concatenate([conv2, units_repeat])\n",
    "\n",
    "\n",
    "# у меня получалось, что батч-нормализация очень сильно тормозит обучение на начальных этапах (подозреваю, что из-за того, что P и P_g почти не ра)\n",
    "def apply_bn_relu_and_dropout(x, bn=False, relu=True, dropout=True):\n",
    "    if bn:\n",
    "        x = BatchNormalization(momentum=0.99, scale=False)(x)\n",
    "    if relu:\n",
    "        x = LeakyReLU()(x)\n",
    "    if dropout:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "with tf.variable_scope('encoder'):\n",
    "    x = Conv2D(32, kernel_size=(3, 3), strides=(2, 2), padding='same')(img)\n",
    "    x = apply_bn_relu_and_dropout(x)\n",
    "    x = MaxPool2D((2, 2), padding='same')(x)\n",
    "\n",
    "    x = Conv2D(64, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = apply_bn_relu_and_dropout(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = concatenate([x, lbl])\n",
    "    \n",
    "    h = Dense(64)(x)\n",
    "    h = apply_bn_relu_and_dropout(h)\n",
    "\n",
    "    z_mean    = Dense(latent_dim)(h)\n",
    "    z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0., stddev=1.0)\n",
    "        return z_mean + K.exp(K.clip(z_log_var/2, -2, 2)) * epsilon\n",
    "    l = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "encoder = Model([img, lbl], [z_mean, z_log_var, l], name='Encoder')\n",
    "\n",
    "\n",
    "with tf.variable_scope('decoder'):\n",
    "    x = concatenate([z, lbl])\n",
    "    x = Dense(7*7*128)(x)\n",
    "    x = apply_bn_relu_and_dropout(x)\n",
    "    x = Reshape((7, 7, 128))(x)\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(64, kernel_size=(5, 5), padding='same')(x)\n",
    "    x = apply_bn_relu_and_dropout(x)\n",
    "\n",
    "    x = Conv2D(32, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = apply_bn_relu_and_dropout(x)\n",
    "    \n",
    "    decoded = Conv2D(1, kernel_size=(5, 5), activation='sigmoid', padding='same')(x)\n",
    "decoder = Model([z, lbl], decoded, name='Decoder')\n",
    "\n",
    "\n",
    "with tf.variable_scope('discrim'):\n",
    "    x = Conv2D(128, kernel_size=(7, 7), strides=(2, 2), padding='same')(img)\n",
    "    x = MaxPool2D((2, 2), padding='same')(x)\n",
    "    x = apply_bn_relu_and_dropout(x)\n",
    "    x = add_units_to_conv2d(x, lbl)\n",
    "\n",
    "    x = Conv2D(64, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = MaxPool2D((2, 2), padding='same')(x)\n",
    "    x = apply_bn_relu_and_dropout(x)\n",
    "\n",
    "    # l-слой на котором будем сравнивать активации\n",
    "    l = Conv2D(16, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = apply_bn_relu_and_dropout(x)\n",
    "\n",
    "    h = Flatten()(x)\n",
    "    d = Dense(1, activation='sigmoid')(h)\n",
    "discrim = Model([img, lbl], [d, l], name='Discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mean, z_log_var, encoded_img = encoder([img, lbl])\n",
    "\n",
    "decoded_img = decoder([encoded_img, lbl])\n",
    "decoded_z   = decoder([z,           lbl])\n",
    "\n",
    "discr_img,     discr_l_img     = discrim([img,         lbl])\n",
    "discr_dec_img, discr_l_dec_img = discrim([decoded_img, lbl])\n",
    "discr_dec_z,   discr_l_dec_z   = discrim([decoded_z,   lbl])\n",
    "\n",
    "cvae_model = Model([img, lbl], decoder([encoded_img, lbl]), name='cvae')\n",
    "cvae =  cvae_model([img, lbl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Базовые лоссы\n",
    "L_prior = -0.5*tf.reduce_sum(1. + tf.clip_by_value(z_log_var, -2, 2) - tf.square(z_mean) - tf.exp(tf.clip_by_value(z_log_var, -2, 2)))/28/28\n",
    "\n",
    "log_dis_img     = tf.log(discr_img + 1e-10)\n",
    "log_dis_dec_z   = tf.log(1. - discr_dec_z + 1e-10)\n",
    "log_dis_dec_img = tf.log(1. - discr_dec_img + 1e-10)\n",
    "\n",
    "L_GAN = -1/4*tf.reduce_sum(log_dis_img + 2*log_dis_dec_z + log_dis_dec_img)/28/28\n",
    "\n",
    "# L_dis_llike = tf.reduce_sum(tf.square(discr_l_img - discr_l_dec_img))/28/28\n",
    "L_dis_llike = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.sigmoid(discr_l_img),\n",
    "                                                                    logits=discr_l_dec_img))/28/28\n",
    "\n",
    "\n",
    "# Лоссы энкодера, декодера, дискриминатора\n",
    "L_enc = L_dis_llike + L_prior \n",
    "L_dec = gamma * L_dis_llike - L_GAN\n",
    "L_dis = L_GAN\n",
    "\n",
    "\n",
    "# Определение шагов оптимизатора\n",
    "optimizer_enc = tf.train.RMSPropOptimizer(0.001)\n",
    "optimizer_dec = tf.train.RMSPropOptimizer(0.0003)\n",
    "optimizer_dis = tf.train.RMSPropOptimizer(0.001)\n",
    "\n",
    "encoder_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"encoder\")\n",
    "decoder_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"decoder\")\n",
    "discrim_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"discrim\")\n",
    "\n",
    "step_enc = optimizer_enc.minimize(L_enc, var_list=encoder_vars)\n",
    "step_dec = optimizer_dec.minimize(L_dec, var_list=decoder_vars)\n",
    "step_dis = optimizer_dis.minimize(L_dis, var_list=discrim_vars)\n",
    "\n",
    "\n",
    "def step(image, label, zp):\n",
    "    l_prior, dec_image, l_dis_llike, l_gan, _, _ = sess.run([L_prior, decoded_z, L_dis_llike, L_GAN, step_enc, step_dec],\n",
    "                                                            feed_dict={z:zp, img:image, lbl:label, K.learning_phase():1})\n",
    "    return l_prior, dec_image, l_dis_llike, l_gan\n",
    "\n",
    "def step_d(image, label, zp):\n",
    "    l_gan, _ = sess.run([L_GAN, step_dis], feed_dict={z:zp, img:image, lbl:label, K.learning_phase():1})\n",
    "    return l_gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_size = 28\n",
    "def plot_digits(*args, invert_colors=False):\n",
    "    args = [x.squeeze() for x in args]\n",
    "    n = min([x.shape[0] for x in args])\n",
    "    figure = np.zeros((digit_size * len(args), digit_size * n))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(len(args)):\n",
    "            figure[j * digit_size: (j + 1) * digit_size,\n",
    "                   i * digit_size: (i + 1) * digit_size] = args[j][i].squeeze()\n",
    "\n",
    "    if invert_colors:\n",
    "        figure = 1-figure\n",
    "\n",
    "    plt.figure(figsize=(2*n, 2*len(args)))\n",
    "    plt.imshow(figure, cmap='Greys_r')\n",
    "    plt.grid(False)\n",
    "    ax = plt.gca()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Массивы, в которые будем сохранять результаты, для последующей визуализации\n",
    "figs = [[] for x in range(num_classes)]\n",
    "periods = []\n",
    "\n",
    "save_periods = list(range(100)) + list(range(100, 1000, 10))\n",
    "\n",
    "n = 15 # Картинка с 15x15 цифр\n",
    "from scipy.stats import norm\n",
    "# Так как сэмплируем из N(0, I), то сетку узлов, в которых генерируем цифры берем из обратной функции распределения\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "def draw_manifold(label, show=True):\n",
    "    # Рисование цифр из многообразия\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    input_lbl = np.zeros((1, 10))\n",
    "    input_lbl[0, label] = 1\n",
    "    for i, yi in enumerate(grid_x):\n",
    "        for j, xi in enumerate(grid_y):\n",
    "            z_sample = np.zeros((1, latent_dim))\n",
    "            z_sample[:, :2] = np.array([[xi, yi]])\n",
    "\n",
    "            x_decoded = sess.run(decoded_z, feed_dict={z:z_sample, lbl:input_lbl, K.learning_phase():0})\n",
    "            digit = x_decoded[0].squeeze()\n",
    "            figure[i * digit_size: (i + 1) * digit_size,\n",
    "                   j * digit_size: (j + 1) * digit_size] = digit\n",
    "    if show:\n",
    "        # Визуализация\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        plt.imshow(figure, cmap='Greys')\n",
    "        plt.grid(False)\n",
    "        ax = plt.gca()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        plt.show()\n",
    "    return figure\n",
    "\n",
    "\n",
    "# Рисование распределения z\n",
    "def draw_z_distr(z_predicted):\n",
    "    im = plt.scatter(z_predicted[:, 0], z_predicted[:, 1])\n",
    "    im.axes.set_xlim(-5, 5)\n",
    "    im.axes.set_ylim(-5, 5)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def on_n_period(period):\n",
    "    n_compare = 10\n",
    "\n",
    "    clear_output() # Не захламляем output\n",
    "\n",
    "    # Сравнение реальных и декодированных цифр\n",
    "    b = next(test_batches_it)\n",
    "    # decoded = sess.run(cvae, feed_dict={img:b[0], lbl:b[1], K.learning_phase():0})\n",
    "    decoded = Model(cvae, feed_dict={img:b[0], lbl:b[1], K.learning_phase():0})\n",
    "    plot_digits(b[0][:n_compare], decoded[:n_compare])\n",
    "\n",
    "    # Рисование многообразия для рандомного y\n",
    "    draw_lbl = np.random.randint(0, num_classes)    \n",
    "    print(draw_lbl)\n",
    "    for label in range(num_classes):\n",
    "        figs[label].append(draw_manifold(label, show=label==draw_lbl))\n",
    "\n",
    "    xs = x_test[y_test == draw_lbl]\n",
    "    ys = y_test_cat[y_test == draw_lbl]\n",
    "    # z_predicted = sess.run(z_mean, feed_dict={img:xs, lbl:ys, K.learning_phase():0})\n",
    "    z_predicted = Model(z_mean, feed_dict={img:xs, lbl:ys, K.learning_phase():0})\n",
    "    draw_z_distr(z_predicted)\n",
    "    \n",
    "    periods.append(period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess.run(tf.global_variables_initializer())\n",
    "\n",
    "nb_step = 3 # Количество шагов во внутреннем цикле\n",
    "\n",
    "batches_per_period = 3\n",
    "for i in range(48000):\n",
    "    print('.', end='')\n",
    "\n",
    "    # Шаги обучения дискриминатора\n",
    "    for j in range(nb_step):\n",
    "        b0, b1 = next(train_batches_it)\n",
    "        zp = np.random.randn(batch_size, latent_dim)\n",
    "        l_g = step_d(b0, b1, zp)\n",
    "        if l_g < 1.0:\n",
    "            break\n",
    "        \n",
    "    # Шаг обучения декодера и энкодера\n",
    "    for j in range(nb_step):\n",
    "        l_p, zx, l_d, l_g = step(b0, b1, zp)\n",
    "        if l_g > 0.4:\n",
    "            break\n",
    "        b0, b1 = next(train_batches_it)\n",
    "        zp = np.random.randn(batch_size, latent_dim)\n",
    "\n",
    "    # Периодическая визуализация результата\n",
    "    if not i % batches_per_period:\n",
    "        period = i // batches_per_period\n",
    "        if period in save_periods:\n",
    "            on_n_period(period)\n",
    "        print(i, l_p, l_d, l_g)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рисовать гифы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib import cm\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "def make_2d_figs_gif(figs, periods, c, fname, fig, batches_per_period): \n",
    "    norm = matplotlib.colors.Normalize(vmin=0, vmax=1, clip=False)\n",
    "    im = plt.imshow(np.zeros((28,28)), cmap='Greys', norm=norm)\n",
    "    plt.grid(None)\n",
    "    plt.title(\"Label: {}\\nBatch: {}\".format(c, 0))\n",
    "\n",
    "    def update(i):\n",
    "        im.set_array(figs[i])\n",
    "        im.axes.set_title(\"Label: {}\\nBatch: {}\".format(c, periods[i]*batches_per_period))\n",
    "        im.axes.get_xaxis().set_visible(False)\n",
    "        im.axes.get_yaxis().set_visible(False)\n",
    "        return im\n",
    "    \n",
    "    anim = FuncAnimation(fig, update, frames=range(len(figs)), interval=100)\n",
    "    anim.save(fname, dpi=80, writer='ffmpeg')\n",
    "\n",
    "for label in range(num_classes):\n",
    "    make_2d_figs_gif(figs[label], periods, label, \"./figs6/manifold_{}.mp4\".format(label), plt.figure(figsize=(10,10)), batches_per_period)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "04635d289a519a1410467dd0afb0db42f9184808881ca68b2eb5a687a20a5a94"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
