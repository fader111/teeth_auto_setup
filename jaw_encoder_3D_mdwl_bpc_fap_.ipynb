{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D энкодер- декодер. Отличие от предыдущей версии - вместо растра точек на вход сети подать вектора лендмарков в виде набора координат и длин.\n",
    "к MDWL добавлены еще 2 лендмарка BCP, FAP - размер энкодера вырос на 3 +3 значения итого 12 значений* 16 зубов = 192."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.datasets import mnist\n",
    "import numpy as np\n",
    "# from jaw_gen import *\n",
    "import tensorflow \n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Lambda\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "# основное отличие - Landmark_gen больше не генерит картинки. только вектора. \n",
    "# и у него теперь есть 3D рисовалка, которая есть независимый метод\n",
    "# генератор теперь в другом файле, генерит дополнительно 2 лендмарка\n",
    "from jaw_gen3d_3lm import Landmark_gen \n",
    "from csv_parser import set_gen_fr_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# готовим СИНТЕТИЧЕСКИЕ входные данные "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SYNT = 0                     # True - учим на синтетике, False - на реальных\n",
    "\n",
    "# готовим СИНТЕТИЧЕСКИЕ входные данные \n",
    "inst_ =                 Landmark_gen()\n",
    "data_len =              5000\n",
    "dataset =               []\n",
    "dataset_spoiled =       []\n",
    "dataset_vec =           []\n",
    "dataset_vec_spoiled =   []\n",
    "\n",
    "if SYNT:\n",
    "    for i in range(data_len):\n",
    "        scale =  9 + np.random.sample()*3     # это для размера 200, диапазон от 14 до 19 для размера 400\n",
    "        factor = 2.2 + np.random.sample()/4   # это для размера 200, диапазон 2.5 - 2.7 для размера 400 \n",
    "        # name = f\"scale {scale:.4}  factor {factor:.3}\"\n",
    "        # сдвиги и генерация остальных лендмарков по умолчанию включены. \n",
    "        vec, vec_spoiled = inst_.image_gen(scale=scale, factor=factor, spoiledMDW=True, shiftMDW=True)\n",
    "\n",
    "        # собираем датасет из векторов \n",
    "        dataset_vec.append(vec)\n",
    "        dataset_vec_spoiled.append(vec_spoiled)\n",
    "    # print (f\"dataset_vec {dataset_vec[:1]}\")\n",
    "    print (f\"dataset_vec len {len(dataset_vec)} \")\n",
    "    print (f\"dataset_vec_spoiled len {len(dataset_vec_spoiled)} \")\n",
    "\n",
    "    # преобразуем датасет в numpy массив\n",
    "    dataset_vec =           np.array(dataset_vec,           dtype=\"float32\") # /2550 тогда не учится ничего \n",
    "    dataset_vec_spoiled =   np.array(dataset_vec_spoiled,   dtype=\"float32\") # /2550\n",
    "\n",
    "# print (f\"datraset vec {dataset_vec[:1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# готовим данные из файла CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data lenght 2398\n"
     ]
    }
   ],
   "source": [
    "# готовим датасет из файла csv\n",
    "# csv_fpath = 'C:/Users/Anton/Projects/jaw_encoder/csv/input_004.csv'\n",
    "# csv_fpath = 'C:/Users/Anton/Projects/jaw_encoder/csv/test10.csv'\n",
    "csv_fpath = 'C:/Users/Anton/Projects/jaw_encoder/csv/input.csv'\n",
    "\n",
    "# выбираем данные из файла\n",
    "if not SYNT:\n",
    "    dataset_vec_spoiled, dataset_vec = set_gen_fr_csv(csv_fpath) # возвращает np массивы сначала T0\n",
    "\n",
    "data_len = len(dataset_vec)\n",
    "print (f\"data lenght {data_len}\")\n",
    "# [print (f\"{i}val {dataset_vec[i][5]} \\n {i}spoil {dataset_vec_spoiled[i][5]}\") for i in range(len(dataset_vec))]\n",
    "# print (f\"val {dataset_vec[3][5]} \\n {dataset_vec_spoiled[3][5]}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length vec         2158 - 240\n",
      "length vec spoil   2158 - 240\n"
     ]
    }
   ],
   "source": [
    "# разобьем датасет на тренировочную и тестовую части\n",
    "set_divider_ = round(data_len*0.9)\n",
    "\n",
    "# векторный датасет\n",
    "x_train_vec =   dataset_vec[:set_divider_]\n",
    "x_test_vec =    dataset_vec[set_divider_:]\n",
    "# print (f\"length vec {len(x_train_vec)} - {len(x_test_vec)}\")\n",
    "\n",
    "x_train_vec_spoiled =   dataset_vec_spoiled[:set_divider_]\n",
    "x_test_vec_spoiled =    dataset_vec_spoiled[set_divider_:]\n",
    "# print (f\"vec [0]{x_test_vec[0]}\")\n",
    "print (f\"length vec         {len(x_train_vec)} - {len(x_test_vec)}\")\n",
    "print (f\"length vec spoil   {len(x_train_vec_spoiled)} - {len(x_test_vec_spoiled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Размерности слоев энкодера \n",
    "dense_dim = 192             # размерность полносвязного слоя энкодера 16 зубов * 12 значений.\n",
    "dim_code = dense_dim//6     # размерность кодированного слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "WITH_BN = 1 # go with batcNormalization\n",
    "def create_vec_ae3D():\n",
    "    # 3d кодер - декодер содержит на входе 12*16=192 значений.\n",
    "    activation = 'elu' \n",
    "    # activation = 'linear'\n",
    "    inputs = Input(dense_dim,)\n",
    "\n",
    "    # encoder\n",
    "    x = Dense(dense_dim, activation=activation)(inputs)\n",
    "    x= BatchNormalization()(x)      if WITH_BN else x\n",
    "    x = Dense(dense_dim, activation=activation)(x)\n",
    "    x= BatchNormalization()(x)      if WITH_BN else x\n",
    "    code = Dense(dim_code, activation='linear')(x)\n",
    "\n",
    "    # decoder\n",
    "    input_encoded = Input((dim_code,))\n",
    "    x = Dense(dim_code, activation=activation)(input_encoded)\n",
    "    x= BatchNormalization()(x)      if WITH_BN else x\n",
    "    x = Dense(dense_dim, activation=activation)(x)\n",
    "    x= BatchNormalization()(x)      if WITH_BN else x\n",
    "    out = Dense(dense_dim, activation='linear')(x)\n",
    "    \n",
    "    # Модели\n",
    "    encoder = Model(inputs, code, name=\"encoder\")\n",
    "    decoder = Model(input_encoded, out, name=\"decoder\")\n",
    "    autoencoder = Model(inputs, decoder(encoder(inputs)), name=\"autoencoder\")\n",
    "    return encoder, decoder, autoencoder\n",
    "\n",
    "encoder, decoder, autoencoder = create_vec_ae3D()\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# autoencoder.compile(Adam(0.0001), loss='mean_squared_error') \n",
    "\n",
    "# c_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "def create_denoising_model(autoencoder):\n",
    "    \n",
    "    inputs  = Input(batch_shape=(batch_size, dense_dim))\n",
    "    inputs_spoiled  = Input(batch_shape=(batch_size, dense_dim)) # вход для кореженных зубьев\n",
    "\n",
    "    denoiser_model = Model([inputs, inputs_spoiled], autoencoder(inputs_spoiled), name=\"denoiser\")\n",
    "    # return noiser, denoiser_model\n",
    "    return denoiser_model\n",
    "\n",
    "\n",
    "# noiser, denoiser_model = create_denoising_model(c_autoencoder)\n",
    "denoiser_model = create_denoising_model(autoencoder)\n",
    "denoiser_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# denoiser_model.compile(Adam(1e-4), loss='mean_squared_error')\n",
    "# optimizer=tf.keras.optimizer.Adam(learning_rate=1e-3)\n",
    "# keras.optimizers.Adam(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_digits(*args):\n",
    "    # for a in args:\n",
    "        # print (f\"type args {type(a)}\")\n",
    "    args = [x.squeeze() for x in args]\n",
    "    n = min([x.shape[0] for x in args])\n",
    "    \n",
    "    plt.figure(figsize=(2*n, 2*len(args)))\n",
    "    for j in range(n):\n",
    "            for i in range(len(args)):\n",
    "                ax = plt.subplot(len(args), n, i*n + j + 1)\n",
    "                plt.imshow(args[i][j])\n",
    "                plt.gray()\n",
    "                ax.get_xaxis().set_visible(False)\n",
    "                ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss -235.19198608398438\n",
      "Epoch 2 loss -214.13043212890625\n",
      "Epoch 5 loss -132.8504638671875\n",
      "Epoch 10 loss -23.922786712646484\n",
      "Epoch 30 loss -10.946481704711914\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15568/2892284412.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'models3D/encoder{epoch}ep_{data_len}len_{batch_size}btsz_bn{WITH_BN}__loss__{loss:.3}__.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m \u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train_vec_spoiled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15568/2892284412.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(vec, vec_spoil, batch_size, epochs)\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mbatch_vec_spoiled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvec_spoil\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdenoiser_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_vec_spoiled\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# эпоха отучилась, построим что вышло.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   1852\u001b[0m       iterator = data_adapter.single_batch_iterator(self.distribute_strategy, x,\n\u001b[0;32m   1853\u001b[0m                                                     \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1854\u001b[1;33m                                                     class_weight)\n\u001b[0m\u001b[0;32m   1855\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1856\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36msingle_batch_iterator\u001b[1;34m(strategy, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1636\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_make_class_weight_map_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1637\u001b[0m   \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_distribute_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1638\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    694\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    716\u001b[0m           gen_dataset_ops.anonymous_iterator_v2(\n\u001b[0;32m    717\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 718\u001b[1;33m               output_shapes=self._flat_output_shapes))\n\u001b[0m\u001b[0;32m    719\u001b[0m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m       \u001b[1;31m# Delete the resource when this object is deleted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36manonymous_iterator_v2\u001b[1;34m(output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m    123\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m    124\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"AnonymousIteratorV2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"output_types\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m         \"output_shapes\", output_shapes)\n\u001b[0m\u001b[0;32m    126\u001b[0m       \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_AnonymousIteratorV2Output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# вместо фита будем делать  model.train_on_batch читобы смотреть как учится и куда движемся \n",
    "# хотя у фита много больше возможностей с колбеками\n",
    "def train_on_batch(vec, vec_spoil, batch_size=batch_size, epochs=100):\n",
    "    # подровняем массив картинок и обучающих векторов так, чтоб np.reshape не ругался - на несовпадение размерности\n",
    "    # сделаем его длину кратной размеру батча\n",
    "    \n",
    "    vec =   vec [:len(x_train_vec)//batch_size*batch_size]\n",
    "    vec =   np.reshape(vec, (-1, batch_size, dense_dim))           # x_test  = np.reshape(x_test,  (len(x_test),  200, 200, 1))\n",
    "    \n",
    "    # и массив кореженных тоже\n",
    "    vec_spoil = vec_spoil   [:len(x_train_vec_spoiled)  //batch_size*batch_size]\n",
    "    vec_spoil = np.reshape(vec_spoil,   (-1, batch_size, dense_dim)) \n",
    "\n",
    "    losses = [10e100] # потери для сравнения эпох будем тут сохранять \n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        # print(f\"Epoch {epoch}\")\n",
    "        for i, _ in enumerate(vec):\n",
    "            batch_vec =         vec[i] \n",
    "            batch_vec_spoiled = vec_spoil[i]\n",
    "\n",
    "            loss = denoiser_model.train_on_batch([batch_vec, batch_vec_spoiled], batch_vec)\n",
    "\n",
    "        # эпоха отучилась, построим что вышло.\n",
    "        n = 10\n",
    "        vecs = batch_vec                    # это последний батч в каждой эпохе.\n",
    "        # print (f\"1! vecs shape{vecs.shape}\") # shape - (256, 64)\n",
    "        noised_vecs = batch_vec_spoiled     \n",
    "        # а картинки не участвуют в учении, количество бачей у них при делении датасета на бачи\n",
    "        # с векторами разное, поэтому найти соответствующую картинку проблематично. \n",
    "        # noised_imgs = noiser.predict(imgs, batch_size=batch_size)\n",
    "\n",
    "        # задача в том, чтобы картинке сопоставить спойленую картинку ( это не сложно из сгенерированной \n",
    "        # выборки сделать), но потом предиктить для этой картинки вектора. и рисовать их на новой картинке \n",
    "        # средствами opencv \n",
    "        encoded_vecs = encoder.predict(noised_vecs[:n],  batch_size=n)\n",
    "        decoded_vecs = decoder.predict(encoded_vecs[:n], batch_size=n)\n",
    "\n",
    "        # формируем картинки из предсказанных векторов\n",
    "        vecs =              np.reshape(vecs,            (-1, 16, dense_dim//16))\n",
    "        noised_vecs =       np.reshape(noised_vecs,     (-1, 16, dense_dim//16))\n",
    "        predicted_vecs =    np.reshape(decoded_vecs,    (-1, 16, dense_dim//16))\n",
    "        \n",
    "        # print (f\"vecs shape{vecs.shape} vecs[0] {vecs[0]}\")\n",
    "        if (epoch%200 ==0) or (epoch in [1,2, 5, 10, 30, 80, 150]):\n",
    "            print(f\"Epoch {epoch} loss -{loss}\")\n",
    "        # рисуем картинки и сохраняем модели\n",
    "        if (epoch % 50 ==0) and (epoch >= 500):\n",
    "            # print(f'Epoch {epoch}')\n",
    "            # plot_digits(batch_x[:n], batch_x_spoil[:n], imgs_fr_vec[:n], imgs_spoil_fr_vec[:n], imgs_fr_decoded_vec[:n])            \n",
    "            if loss < min(losses):\n",
    "                losses.append(loss)\n",
    "                # save only the best models\n",
    "                #denoiser_model.save(f'models3D/denoiser{epoch}ep_loss__{loss:.3}__.h5')\n",
    "                decoder.save(f'models3D/decoder{epoch}ep_{data_len}len_{batch_size}btsz_bn{WITH_BN}__loss__{loss:.3}__.h5')\n",
    "                encoder.save(f'models3D/encoder{epoch}ep_{data_len}len_{batch_size}btsz_bn{WITH_BN}__loss__{loss:.3}__.h5')\n",
    "        \n",
    "train_on_batch(x_train_vec, x_train_vec_spoiled, batch_size=batch_size, epochs=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_autoencoder.save(f'models/c_autoencoder.h5'"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "04635d289a519a1410467dd0afb0db42f9184808881ca68b2eb5a687a20a5a94"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
