{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "3D энкодер- декодер. Отличие от предыдущей версии - вместо растра точек на вход сети подать вектора лендмарков в виде набора координат и длин.\r\n",
    "к MDWL добавлены еще 2 лендмарка BCP, FAP - размер энкодера вырос на 3 +3 значения итого 12 значений* 16 зубов = 192."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# from keras.datasets import mnist\r\n",
    "import numpy as np\r\n",
    "# from jaw_gen import *\r\n",
    "import tensorflow as tf \r\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Dropout\r\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization\r\n",
    "from tensorflow.keras.models import Model\r\n",
    "from tensorflow.keras.optimizers import Adam\r\n",
    "\r\n",
    "import tensorflow.keras.backend as K\r\n",
    "from tensorflow.keras.layers import Lambda\r\n",
    "import cv2\r\n",
    "\r\n",
    "from tqdm import tqdm\r\n",
    "# основное отличие - Landmark_gen больше не генерит картинки. только вектора. \r\n",
    "# и у него теперь есть 3D рисовалка, которая есть независимый метод\r\n",
    "# генератор теперь в другом файле, генерит дополнительно 2 лендмарка\r\n",
    "from jaw_gen3d_3lm import Landmark_gen "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# готовим входные данные\r\n",
    "inst_ =                 Landmark_gen()\r\n",
    "data_len =              50000\r\n",
    "dataset =               []\r\n",
    "dataset_spoiled =       []\r\n",
    "dataset_vec =           []\r\n",
    "dataset_vec_spoiled =   []\r\n",
    "\r\n",
    "for i in range(data_len):\r\n",
    "    scale =  9 + np.random.sample()*3     # это для размера 200, диапазон от 14 до 19 для размера 400\r\n",
    "    factor = 2.2 + np.random.sample()/4   # это для размера 200, диапазон 2.5 - 2.7 для размера 400 \r\n",
    "    # name = f\"scale {scale:.4}  factor {factor:.3}\"\r\n",
    "    # сдвиги и генерация остальных лендмарков по умолчанию включены. \r\n",
    "    vec, vec_spoiled = inst_.image_gen(scale=scale, factor=factor, spoiledMDW=True, shiftMDW=True)\r\n",
    "    # dataset.append(img_)\r\n",
    "    # dataset_spoiled.append(img_spoiled_)\r\n",
    "\r\n",
    "    # собираем датасет из векторов \r\n",
    "    dataset_vec.append(vec)\r\n",
    "    dataset_vec_spoiled.append(vec_spoiled)\r\n",
    "# print (f\"dataset_vec {dataset_vec[:1]}\")\r\n",
    "print (f\"dataset_vec len {len(dataset_vec)} \")\r\n",
    "print (f\"dataset_vec_spoiled len {len(dataset_vec_spoiled)} \")\r\n",
    "\r\n",
    "# преобразуем датасет в numpy массив\r\n",
    "# dataset =               np.array(dataset,               dtype=\"float32\")    # x_train = x_train.astype('float32') / 255. \r\n",
    "# dataset_spoiled =       np.array(dataset_spoiled,       dtype=\"float32\") \r\n",
    "dataset_vec =           np.array(dataset_vec,           dtype=\"float32\") \r\n",
    "dataset_vec_spoiled =   np.array(dataset_vec_spoiled,   dtype=\"float32\") \r\n",
    "\r\n",
    "# dataset =           np.reshape(dataset,         (len(dataset), 200, 200, 1))\r\n",
    "# dataset_spoiled =   np.reshape(dataset_spoiled, (len(dataset_spoiled), 200, 200, 1))\r\n",
    "\r\n",
    "# разобьем датасет на тренировочную и тестовую части\r\n",
    "set_divider_ = round(data_len*0.8)\r\n",
    "# print (f\"set_divider_ {set_divider_}\")\r\n",
    "\r\n",
    "# x_train = dataset[:set_divider_]\r\n",
    "# x_test = dataset[set_divider_:]\r\n",
    "# print (f\"length {len(x_train)} - {len(x_test)}\")\r\n",
    "\r\n",
    "# x_train_spoiled = dataset_spoiled[:set_divider_]\r\n",
    "# x_test_spoiled = dataset_spoiled[set_divider_:]\r\n",
    "\r\n",
    "# векторный датасет\r\n",
    "x_train_vec =   dataset_vec[:set_divider_]\r\n",
    "x_test_vec =    dataset_vec[set_divider_:]\r\n",
    "# print (f\"length vec {len(x_train_vec)} - {len(x_test_vec)}\")\r\n",
    "\r\n",
    "x_train_vec_spoiled =   dataset_vec_spoiled[:set_divider_]\r\n",
    "x_test_vec_spoiled =    dataset_vec_spoiled[set_divider_:]\r\n",
    "# print (f\"vec [0]{x_test_vec[0]}\")\r\n",
    "print (f\"length vec         {len(x_train_vec)} - {len(x_test_vec)}\")\r\n",
    "print (f\"length vec spoil   {len(x_train_vec_spoiled)} - {len(x_test_vec_spoiled)}\")\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dataset_vec len 50000 \n",
      "dataset_vec_spoiled len 50000 \n",
      "length vec         40000 - 10000\n",
      "length vec spoil   40000 - 10000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Размерности слоев энкодера \r\n",
    "dense_dim = 192             # размерность полносвязного слоя энкодера 16 зубов * 12 значений.\r\n",
    "dim_code = dense_dim//6     # размерность кодированного слоя"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def create_vec_ae3D():\r\n",
    "    # 3d кодер - декодер содержит на входе 12*16=192 значений.\r\n",
    "    activation = 'elu' \r\n",
    "    # activation = 'linear'\r\n",
    "    inputs = Input(dense_dim,)\r\n",
    "    WITH_BN = True # go with batcNormalization\r\n",
    "\r\n",
    "    # encoder\r\n",
    "    x = Dense(dense_dim, activation=activation)(inputs)\r\n",
    "    x= BatchNormalization()(x)      if WITH_BN else x\r\n",
    "    x = Dense(dense_dim, activation=activation)(x)\r\n",
    "    x= BatchNormalization()(x)      if WITH_BN else x\r\n",
    "    code = Dense(dim_code, activation='linear')(x)\r\n",
    "\r\n",
    "    # decoder\r\n",
    "    input_encoded = Input((dim_code,))\r\n",
    "    x = Dense(dim_code, activation=activation)(input_encoded)\r\n",
    "    x= BatchNormalization()(x)      if WITH_BN else x\r\n",
    "    x = Dense(dense_dim, activation=activation)(x)\r\n",
    "    x= BatchNormalization()(x)      if WITH_BN else x\r\n",
    "    out = Dense(dense_dim, activation='linear')(x)\r\n",
    "    \r\n",
    "    # Модели\r\n",
    "    encoder = Model(inputs, code, name=\"encoder\")\r\n",
    "    decoder = Model(input_encoded, out, name=\"decoder\")\r\n",
    "    autoencoder = Model(inputs, decoder(encoder(inputs)), name=\"autoencoder\")\r\n",
    "    return encoder, decoder, autoencoder\r\n",
    "\r\n",
    "encoder, decoder, autoencoder = create_vec_ae3D()\r\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\r\n",
    "# autoencoder.compile(Adam(0.003), 'mse') # не имело особого эффекта\r\n",
    "\r\n",
    "# c_autoencoder.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "batch_size = 256\r\n",
    "\r\n",
    "def create_denoising_model(autoencoder):\r\n",
    "    \r\n",
    "    inputs  = Input(batch_shape=(batch_size, dense_dim))\r\n",
    "    inputs_spoiled  = Input(batch_shape=(batch_size, dense_dim)) # вход для кореженных зубьев\r\n",
    "\r\n",
    "    denoiser_model = Model([inputs, inputs_spoiled], autoencoder(inputs_spoiled), name=\"denoiser\")\r\n",
    "    # return noiser, denoiser_model\r\n",
    "    return denoiser_model\r\n",
    "\r\n",
    "\r\n",
    "# noiser, denoiser_model = create_denoising_model(c_autoencoder)\r\n",
    "denoiser_model = create_denoising_model(autoencoder)\r\n",
    "denoiser_model.compile(optimizer='adam', loss='mean_squared_error')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "%matplotlib inline\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "def plot_digits(*args):\r\n",
    "    # for a in args:\r\n",
    "        # print (f\"type args {type(a)}\")\r\n",
    "    args = [x.squeeze() for x in args]\r\n",
    "    n = min([x.shape[0] for x in args])\r\n",
    "    \r\n",
    "    plt.figure(figsize=(2*n, 2*len(args)))\r\n",
    "    for j in range(n):\r\n",
    "            for i in range(len(args)):\r\n",
    "                ax = plt.subplot(len(args), n, i*n + j + 1)\r\n",
    "                plt.imshow(args[i][j])\r\n",
    "                plt.gray()\r\n",
    "                ax.get_xaxis().set_visible(False)\r\n",
    "                ax.get_yaxis().set_visible(False)\r\n",
    "\r\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "%matplotlib inline\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "def plot_3d(*args):\r\n",
    "    # \r\n",
    "    n = min([x.shape[0] for x in args]) # сколько столбцов\r\n",
    "    plt.figure(figsize=(2*n, 2*len(args)))\r\n",
    "    for j in range(n):\r\n",
    "        for i in range(len(args)):\r\n",
    "            pass #ax = plt.\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# вместо фита будем делать  model.train_on_batch читобы смотреть как учится и куда движемся \r\n",
    "# хотя у фита много больше возможностей с колбеками\r\n",
    "def train_on_batch(vec, vec_spoil, batch_size=batch_size, epochs=100):\r\n",
    "    # подровняем массив картинок и обучающих векторов так, чтоб np.reshape не ругался - на несовпадение размерности\r\n",
    "    # сделаем его длину кратной размеру батча\r\n",
    "    # print (f\"x_train_vec.shape {x_train_vec.shape}\")    # (8000, 16, 6)\r\n",
    "    # print (f\"vec shape {vec.shape}\")                    # (8000, 16, 6)\r\n",
    "    # print (f\"vec_spoil shape {vec_spoil.shape}\")        # (8000, 16, 6)\r\n",
    "\r\n",
    "    # x =     x   [:len(x_train)//    batch_size*batch_size]\r\n",
    "    vec =   vec [:len(x_train_vec)//batch_size*batch_size]\r\n",
    "    # x =     np.reshape(x,   (-1, batch_size, 200, 200, 1))  # x_test  = np.reshape(x_test,  (len(x_test),  200, 200, 1))\r\n",
    "    vec =   np.reshape(vec, (-1, batch_size, dense_dim))           # x_test  = np.reshape(x_test,  (len(x_test),  200, 200, 1))\r\n",
    "    \r\n",
    "    # и массив кореженных тоже\r\n",
    "    # x_spoil =   x_spoil     [:len(x_train_spoiled)      //batch_size*batch_size]\r\n",
    "    vec_spoil = vec_spoil   [:len(x_train_vec_spoiled)  //batch_size*batch_size]\r\n",
    "    # x_spoil =   np.reshape(x_spoil,     (-1, batch_size, 200, 200, 1)) \r\n",
    "    vec_spoil = np.reshape(vec_spoil,   (-1, batch_size, dense_dim)) \r\n",
    "\r\n",
    "    # print (f\"\\nvec shape {vec.shape}\")                  # (31, 256, dense_dim)\r\n",
    "    # print (f\"vec_spoil shape {vec_spoil.shape}\")        # (31, 256, dense_dim)\r\n",
    "    losses = [10e100] # потери для сравнения эпох будем тут сохранять \r\n",
    "\r\n",
    "    for epoch in range(1, epochs+1):\r\n",
    "        # print(f\"Epoch {epoch}\")\r\n",
    "        for i, _ in enumerate(vec):\r\n",
    "            # batch_x =           x[i]\r\n",
    "            # batch_x_spoil =     x_spoil[i]    \r\n",
    "            batch_vec =         vec[i] \r\n",
    "            batch_vec_spoiled = vec_spoil[i]\r\n",
    "\r\n",
    "            loss = denoiser_model.train_on_batch([batch_vec, batch_vec_spoiled], batch_vec)\r\n",
    "\r\n",
    "        # эпоха отучилась, построим что вышло.\r\n",
    "        n = 10\r\n",
    "        vecs = batch_vec                    # это последний батч в каждой эпохе.\r\n",
    "        # print (f\"1! vecs shape{vecs.shape}\") # shape - (256, 64)\r\n",
    "        noised_vecs = batch_vec_spoiled     \r\n",
    "        # а картинки не участвуют в учении, количество бачей у них при делении датасета на бачи\r\n",
    "        # с векторами разное, поэтому найти соответствующую картинку проблематично. \r\n",
    "        # noised_imgs = noiser.predict(imgs, batch_size=batch_size)\r\n",
    "\r\n",
    "        # задача в том, чтобы картинке сопоставить спойленую картинку ( это не сложно из сгенерированной \r\n",
    "        # выборки сделать), но потом предиктить для этой картинки вектора. и рисовать их на новой картинке \r\n",
    "        # средствами opencv \r\n",
    "        encoded_vecs = encoder.predict(noised_vecs[:n],  batch_size=n)\r\n",
    "        decoded_vecs = decoder.predict(encoded_vecs[:n], batch_size=n)\r\n",
    "\r\n",
    "        # формируем картинки из предсказанных векторов\r\n",
    "        vecs =              np.reshape(vecs,            (-1, 16, dense_dim//16))\r\n",
    "        noised_vecs =       np.reshape(noised_vecs,     (-1, 16, dense_dim//16))\r\n",
    "        predicted_vecs =    np.reshape(decoded_vecs,    (-1, 16, dense_dim//16))\r\n",
    "        \r\n",
    "        # print (f\"vecs shape{vecs.shape} vecs[0] {vecs[0]}\")\r\n",
    "        \r\n",
    "        # imgs_fr_vec =           np.array([im for im in map(inst_.draw_3d, (noised_vecs,predicted_vecs) )])\r\n",
    "        # imgs_spoil_fr_vec =     np.array([im for im in map(inst_.draw_3d, noised_vecs)])\r\n",
    "        # imgs_fr_decoded_vec =   np.array([im for im in map(inst_.draw_3d, predicted_vecs)])\r\n",
    "\r\n",
    "        # print (f\"batch_x shape{     np.array(batch_x).shape}\")      # (256, 200, 200, 1)\r\n",
    "        # print (f\"imgs_fr_vec shape{ np.array(imgs_fr_vec).shape}\")  # (256, 200, 200)\r\n",
    "        if (epoch%200 ==0) or (epoch in [1,2, 5, 10, 30, 80, 150]):\r\n",
    "            print(f\"Epoch {epoch} loss -{loss}\")\r\n",
    "        # рисуем картинки и сохраняем модели\r\n",
    "        if (epoch % 200 ==0) and (epoch >= 800):\r\n",
    "            # print(f'Epoch {epoch}')\r\n",
    "            # plot_digits(batch_x[:n], batch_x_spoil[:n], imgs_fr_vec[:n], imgs_spoil_fr_vec[:n], imgs_fr_decoded_vec[:n])            \r\n",
    "            # plot_digits(imgs_fr_vec[:n][0], imgs_spoil_fr_vec[:n], imgs_fr_decoded_vec[:n])\r\n",
    "            ##########plot_digits(imgs_fr_vec[:n])\r\n",
    "            # plot_digits(batch_x[:n], batch_x_spoil[:n])\r\n",
    "            if loss < min(losses):\r\n",
    "                losses.append(loss)\r\n",
    "                # save only the best models\r\n",
    "                denoiser_model.save(f'models3D/denoiser{epoch}ep_loss__{loss:.3}__.h5')\r\n",
    "                decoder.save(f'models3D/decoder{epoch}ep_loss__{loss:.3}__.h5')\r\n",
    "                encoder.save(f'models3D/encoder{epoch}ep_loss__{loss:.3}__.h5')\r\n",
    "        \r\n",
    "train_on_batch(x_train_vec, x_train_vec_spoiled, batch_size=batch_size, epochs=5000)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 loss -5557.3271484375\n",
      "Epoch 2 loss -2681.520751953125\n",
      "Epoch 5 loss -53.64216995239258\n",
      "Epoch 10 loss -0.1127583384513855\n",
      "Epoch 30 loss -0.07116470485925674\n",
      "Epoch 80 loss -0.0782487764954567\n",
      "Epoch 150 loss -0.06411002576351166\n",
      "Epoch 200 loss -0.05603867769241333\n",
      "Epoch 400 loss -0.05232542008161545\n",
      "Epoch 600 loss -0.053986262530088425\n",
      "Epoch 800 loss -0.04777858406305313\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 1000 loss -0.04471577703952789\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 1200 loss -0.045089781284332275\n",
      "Epoch 1400 loss -0.044835418462753296\n",
      "Epoch 1600 loss -0.042343392968177795\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 1800 loss -0.043069399893283844\n",
      "Epoch 2000 loss -0.042311497032642365\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 2200 loss -0.04249465465545654\n",
      "Epoch 2400 loss -0.04204666614532471\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 2600 loss -0.04159945249557495\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 2800 loss -0.041493672877550125\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 3000 loss -0.04150089994072914\n",
      "Epoch 3200 loss -0.041141726076602936\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 3400 loss -0.04091506078839302\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 3600 loss -0.04434644430875778\n",
      "Epoch 3800 loss -0.04217198118567467\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14276/1283868326.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'models3D/encoder{epoch}ep_loss__{loss:.3}__.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m \u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train_vec_spoiled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14276/1283868326.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(vec, vec_spoil, batch_size, epochs)\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mbatch_vec_spoiled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvec_spoil\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdenoiser_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_vec_spoiled\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# эпоха отучилась, построим что вышло.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   1854\u001b[0m                                                     class_weight)\n\u001b[0;32m   1855\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1856\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1858\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3040\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1964\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# c_autoencoder.save(f'models/c_autoencoder.h5'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "encoded_imgs[:20]"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit"
  },
  "interpreter": {
   "hash": "04635d289a519a1410467dd0afb0db42f9184808881ca68b2eb5a687a20a5a94"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}